{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML классификатор на основе нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20   21   22   23   24   25   26   27    28\n",
      "0     1.000000  0.949765  0.946863  0.890311  0.886746  0.810817  0.768762  0.702327  0.658250  0.519462  0.000000  0.071725  0.156965  0.237875  0.342755  0.385964  0.561642  0.618664  0.710416  0.721658  0.876098  1.0  0.0  0.0  0.0  0.0  0.0  0.0  down\n",
      "1     1.000000  0.999613  0.949249  0.946274  0.888331  0.884700  0.808215  0.764843  0.699029  0.650257  0.510770  0.000000  0.073884  0.163346  0.246354  0.359640  0.402954  0.585638  0.643909  0.737880  0.749382  0.0  1.0  0.0  0.0  0.0  0.0  0.0    up\n",
      "2     0.879807  0.815902  0.811820  0.731742  0.685201  0.616099  0.559507  0.401556  0.216736  0.112487  0.000000  0.101511  0.235431  0.280920  0.482243  0.544868  0.668686  0.686063  0.859401  0.888299  1.000000  0.0  0.0  0.0  1.0  0.0  0.0  0.0  down\n",
      "3     0.948702  0.944897  0.878314  0.873936  0.785999  0.735860  0.661449  0.599869  0.418103  0.218242  0.095601  0.000000  0.115987  0.275745  0.324956  0.549744  0.621755  0.756995  0.775867  0.968883  1.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  down\n",
      "...        ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
      "2360  0.923117  0.921823  0.917817  0.913042  0.898110  0.895035  0.862947  0.828956  0.770526  0.728078  0.603852  0.000000  0.323312  0.716141  0.818557  0.908793  0.941448  0.973334  0.992393  0.996480  1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0    up\n",
      "2361  0.963947  0.959395  0.954555  0.939420  0.936303  0.902383  0.865674  0.801977  0.747180  0.600098  0.000000  0.332062  0.708585  0.807309  0.904147  0.937943  0.970715  0.990033  0.994176  0.997744  1.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0    up\n",
      "2362  1.000000  0.993306  0.986191  0.963879  0.959296  0.903274  0.843756  0.740578  0.644817  0.414943  0.027679  0.000000  0.537297  0.684737  0.827715  0.878249  0.927335  0.956341  0.962431  0.967678  0.970934  0.0  0.0  1.0  0.0  0.0  0.0  0.0  down\n",
      "2363  1.000000  0.989684  0.978200  0.942092  0.934599  0.872019  0.817810  0.710170  0.604185  0.332457  0.000000  0.244866  0.455280  0.588516  0.713771  0.758540  0.817810  0.861703  0.870462  0.878929  0.884185  0.0  0.0  0.0  1.0  0.0  0.0  0.0  down\n"
     ]
    }
   ],
   "source": [
    "# Загружаем файл с разделителем ';' в DF\n",
    "df = pd.read_csv(fr'nn_features_and_target.csv', delimiter=';')\n",
    "# df.columns = df.columns.astype(str)\n",
    "# df['29'] = df.apply(lambda x: 1.0 if x['28'] == 0.0 else 0.0, axis=1)\n",
    "print(df.to_string(max_rows=8, max_cols=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'up' 'down' ... 'up' 'down' 'down']\n"
     ]
    }
   ],
   "source": [
    "# Разделяем датафрейм на признаки (X) и целевую переменную (y)\n",
    "X = df.drop('28', axis=1).values\n",
    "y = df['28'].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем категориальный таргет в числовой формат\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем числовые метки в one-hot encoding\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "print(y_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Разделяем данные на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель нейронной сети\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))  # Входной слой\n",
    "for _ in range(4):\n",
    "    model.add(Dense(1024, activation='relu', ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.20))\n",
    "# model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))  # Выходной слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Компилируем модель по параметрам\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5128 - loss: 1.8923 - val_accuracy: 0.4960 - val_loss: 0.7004\n",
      "Epoch 2/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4872 - loss: 1.0373 - val_accuracy: 0.4776 - val_loss: 0.7194\n",
      "Epoch 3/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4980 - loss: 0.8792 - val_accuracy: 0.4723 - val_loss: 0.8408\n",
      "Epoch 4/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5082 - loss: 0.8404 - val_accuracy: 0.5277 - val_loss: 0.7061\n",
      "Epoch 5/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4985 - loss: 0.8417 - val_accuracy: 0.5013 - val_loss: 0.7212\n",
      "Epoch 6/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5369 - loss: 0.7453 - val_accuracy: 0.5013 - val_loss: 0.7082\n",
      "Epoch 7/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4973 - loss: 0.8060 - val_accuracy: 0.4855 - val_loss: 0.7563\n",
      "Epoch 8/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.7647 - val_accuracy: 0.5013 - val_loss: 0.7729\n",
      "Epoch 9/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5133 - loss: 0.7604 - val_accuracy: 0.4908 - val_loss: 0.7876\n",
      "Epoch 10/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5297 - loss: 0.7485 - val_accuracy: 0.4987 - val_loss: 0.7353\n",
      "Epoch 11/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5282 - loss: 0.7386 - val_accuracy: 0.4485 - val_loss: 0.7487\n",
      "Epoch 12/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5188 - loss: 0.7806 - val_accuracy: 0.5013 - val_loss: 0.8093\n",
      "Epoch 13/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5130 - loss: 0.7751 - val_accuracy: 0.4934 - val_loss: 0.7331\n",
      "Epoch 14/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4817 - loss: 0.7722 - val_accuracy: 0.5040 - val_loss: 0.7120\n",
      "Epoch 15/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5429 - loss: 0.7228 - val_accuracy: 0.5119 - val_loss: 0.7527\n",
      "Epoch 16/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5348 - loss: 0.7143 - val_accuracy: 0.4802 - val_loss: 0.7654\n",
      "Epoch 17/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5494 - loss: 0.7190 - val_accuracy: 0.5092 - val_loss: 0.7190\n",
      "Epoch 18/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5610 - loss: 0.7016 - val_accuracy: 0.5066 - val_loss: 0.7836\n",
      "Epoch 19/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5552 - loss: 0.7225 - val_accuracy: 0.4960 - val_loss: 0.7372\n",
      "Epoch 20/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5537 - loss: 0.7116 - val_accuracy: 0.5066 - val_loss: 0.7715\n",
      "Epoch 21/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5291 - loss: 0.7259 - val_accuracy: 0.5092 - val_loss: 0.7978\n",
      "Epoch 22/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5534 - loss: 0.7240 - val_accuracy: 0.4987 - val_loss: 0.7743\n",
      "Epoch 23/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5515 - loss: 0.7134 - val_accuracy: 0.4960 - val_loss: 0.7549\n",
      "Epoch 24/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5531 - loss: 0.6959 - val_accuracy: 0.5330 - val_loss: 0.7614\n",
      "Epoch 25/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5625 - loss: 0.7066 - val_accuracy: 0.5224 - val_loss: 0.7864\n",
      "Epoch 26/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5438 - loss: 0.7147 - val_accuracy: 0.5119 - val_loss: 0.7591\n",
      "Epoch 27/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5754 - loss: 0.7160 - val_accuracy: 0.5145 - val_loss: 0.8192\n",
      "Epoch 28/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5433 - loss: 0.7319 - val_accuracy: 0.4828 - val_loss: 0.7555\n",
      "Epoch 29/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5641 - loss: 0.6865 - val_accuracy: 0.4934 - val_loss: 0.8248\n",
      "Epoch 30/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5657 - loss: 0.7114 - val_accuracy: 0.5277 - val_loss: 0.7570\n",
      "Epoch 31/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5528 - loss: 0.6933 - val_accuracy: 0.5066 - val_loss: 0.7423\n",
      "Epoch 32/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5616 - loss: 0.7031 - val_accuracy: 0.4908 - val_loss: 0.7431\n",
      "Epoch 33/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5687 - loss: 0.6868 - val_accuracy: 0.5092 - val_loss: 0.8391\n",
      "Epoch 34/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5578 - loss: 0.7157 - val_accuracy: 0.5119 - val_loss: 0.7707\n",
      "Epoch 35/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5777 - loss: 0.6989 - val_accuracy: 0.4908 - val_loss: 0.7450\n",
      "Epoch 36/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5591 - loss: 0.7310 - val_accuracy: 0.4960 - val_loss: 0.7900\n",
      "Epoch 37/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5360 - loss: 0.7233 - val_accuracy: 0.4776 - val_loss: 0.8090\n",
      "Epoch 38/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5421 - loss: 0.7254 - val_accuracy: 0.5172 - val_loss: 0.7413\n",
      "Epoch 39/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5811 - loss: 0.6920 - val_accuracy: 0.5092 - val_loss: 0.7318\n",
      "Epoch 40/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5693 - loss: 0.6910 - val_accuracy: 0.4934 - val_loss: 0.8366\n",
      "Epoch 41/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5689 - loss: 0.7095 - val_accuracy: 0.5356 - val_loss: 0.7464\n",
      "Epoch 42/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5658 - loss: 0.6903 - val_accuracy: 0.5040 - val_loss: 0.7610\n",
      "Epoch 43/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5785 - loss: 0.6843 - val_accuracy: 0.5224 - val_loss: 0.7941\n",
      "Epoch 44/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5503 - loss: 0.7244 - val_accuracy: 0.5066 - val_loss: 0.7879\n",
      "Epoch 45/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5808 - loss: 0.7074 - val_accuracy: 0.4987 - val_loss: 0.7814\n",
      "Epoch 46/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5701 - loss: 0.6850 - val_accuracy: 0.4987 - val_loss: 0.8340\n",
      "Epoch 47/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5911 - loss: 0.6842 - val_accuracy: 0.5224 - val_loss: 0.7739\n",
      "Epoch 48/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5725 - loss: 0.6931 - val_accuracy: 0.5172 - val_loss: 0.8197\n",
      "Epoch 49/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5989 - loss: 0.6865 - val_accuracy: 0.4697 - val_loss: 0.7753\n",
      "Epoch 50/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5764 - loss: 0.6999 - val_accuracy: 0.4934 - val_loss: 0.7942\n",
      "Epoch 51/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5918 - loss: 0.6803 - val_accuracy: 0.5013 - val_loss: 0.8233\n",
      "Epoch 52/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5751 - loss: 0.7178 - val_accuracy: 0.5119 - val_loss: 0.7936\n",
      "Epoch 53/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5875 - loss: 0.6893 - val_accuracy: 0.5092 - val_loss: 0.7601\n",
      "Epoch 54/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6084 - loss: 0.6704 - val_accuracy: 0.5092 - val_loss: 0.7915\n",
      "Epoch 55/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5863 - loss: 0.6866 - val_accuracy: 0.5040 - val_loss: 0.7493\n",
      "Epoch 56/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5789 - loss: 0.6839 - val_accuracy: 0.5040 - val_loss: 0.7624\n",
      "Epoch 57/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5635 - loss: 0.6988 - val_accuracy: 0.4776 - val_loss: 0.7830\n",
      "Epoch 58/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5781 - loss: 0.6924 - val_accuracy: 0.5224 - val_loss: 0.7736\n",
      "Epoch 59/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5850 - loss: 0.6915 - val_accuracy: 0.4934 - val_loss: 0.8021\n",
      "Epoch 60/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6008 - loss: 0.6775 - val_accuracy: 0.5488 - val_loss: 0.8167\n",
      "Epoch 61/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5789 - loss: 0.7076 - val_accuracy: 0.5040 - val_loss: 0.8023\n",
      "Epoch 62/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6127 - loss: 0.6575 - val_accuracy: 0.5172 - val_loss: 0.7932\n",
      "Epoch 63/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5857 - loss: 0.6842 - val_accuracy: 0.4987 - val_loss: 0.8302\n",
      "Epoch 64/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6133 - loss: 0.6875 - val_accuracy: 0.4987 - val_loss: 0.7910\n",
      "Epoch 65/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5976 - loss: 0.6830 - val_accuracy: 0.4802 - val_loss: 0.7685\n",
      "Epoch 66/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5382 - loss: 0.7077 - val_accuracy: 0.5119 - val_loss: 0.7971\n",
      "Epoch 67/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6111 - loss: 0.6576 - val_accuracy: 0.4960 - val_loss: 0.8149\n",
      "Epoch 68/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6095 - loss: 0.6787 - val_accuracy: 0.4828 - val_loss: 0.7837\n",
      "Epoch 69/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5823 - loss: 0.7019 - val_accuracy: 0.4960 - val_loss: 0.8340\n",
      "Epoch 70/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6115 - loss: 0.6879 - val_accuracy: 0.5330 - val_loss: 0.7691\n",
      "Epoch 71/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5878 - loss: 0.6910 - val_accuracy: 0.4987 - val_loss: 0.7766\n",
      "Epoch 72/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6152 - loss: 0.6594 - val_accuracy: 0.5040 - val_loss: 0.8487\n",
      "Epoch 73/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6124 - loss: 0.6633 - val_accuracy: 0.5277 - val_loss: 0.8558\n",
      "Epoch 74/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5793 - loss: 0.6988 - val_accuracy: 0.4987 - val_loss: 0.8211\n",
      "Epoch 75/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5823 - loss: 0.6891 - val_accuracy: 0.5066 - val_loss: 0.7789\n",
      "Epoch 76/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6076 - loss: 0.6793 - val_accuracy: 0.5092 - val_loss: 0.8259\n",
      "Epoch 77/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5932 - loss: 0.6849 - val_accuracy: 0.5145 - val_loss: 0.8506\n",
      "Epoch 78/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5924 - loss: 0.6952 - val_accuracy: 0.4881 - val_loss: 0.8026\n",
      "Epoch 79/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6142 - loss: 0.6764 - val_accuracy: 0.5013 - val_loss: 0.7873\n",
      "Epoch 80/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6454 - loss: 0.6410 - val_accuracy: 0.4802 - val_loss: 0.7895\n",
      "Epoch 81/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6014 - loss: 0.6657 - val_accuracy: 0.4987 - val_loss: 0.9188\n",
      "Epoch 82/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6201 - loss: 0.6569 - val_accuracy: 0.5092 - val_loss: 0.8446\n",
      "Epoch 83/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6538 - loss: 0.6314 - val_accuracy: 0.5013 - val_loss: 0.7673\n",
      "Epoch 84/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5759 - loss: 0.6714 - val_accuracy: 0.4881 - val_loss: 0.7751\n",
      "Epoch 85/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6153 - loss: 0.6660 - val_accuracy: 0.5119 - val_loss: 0.7685\n",
      "Epoch 86/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6255 - loss: 0.6510 - val_accuracy: 0.5172 - val_loss: 0.8269\n",
      "Epoch 87/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6367 - loss: 0.6338 - val_accuracy: 0.5092 - val_loss: 0.7732\n",
      "Epoch 88/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6341 - loss: 0.6348 - val_accuracy: 0.5251 - val_loss: 0.9014\n",
      "Epoch 89/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6331 - loss: 0.6488 - val_accuracy: 0.5040 - val_loss: 0.7981\n",
      "Epoch 90/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6462 - loss: 0.6237 - val_accuracy: 0.5198 - val_loss: 0.8311\n",
      "Epoch 91/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5965 - loss: 0.6810 - val_accuracy: 0.5251 - val_loss: 0.8058\n",
      "Epoch 92/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6073 - loss: 0.6624 - val_accuracy: 0.4960 - val_loss: 0.8866\n",
      "Epoch 93/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6517 - loss: 0.6285 - val_accuracy: 0.5145 - val_loss: 0.8043\n",
      "Epoch 94/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6157 - loss: 0.6777 - val_accuracy: 0.5224 - val_loss: 0.8503\n",
      "Epoch 95/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6234 - loss: 0.6624 - val_accuracy: 0.4565 - val_loss: 0.8611\n",
      "Epoch 96/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6506 - loss: 0.6300 - val_accuracy: 0.4855 - val_loss: 0.8666\n",
      "Epoch 97/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6371 - loss: 0.6368 - val_accuracy: 0.4697 - val_loss: 0.9488\n",
      "Epoch 98/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6495 - loss: 0.6396 - val_accuracy: 0.4908 - val_loss: 0.8363\n",
      "Epoch 99/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6477 - loss: 0.6254 - val_accuracy: 0.4881 - val_loss: 0.8255\n",
      "Epoch 100/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6567 - loss: 0.6219 - val_accuracy: 0.5145 - val_loss: 0.8401\n",
      "Epoch 101/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6220 - loss: 0.6440 - val_accuracy: 0.4828 - val_loss: 0.8553\n",
      "Epoch 102/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6577 - loss: 0.6153 - val_accuracy: 0.4670 - val_loss: 0.8454\n",
      "Epoch 103/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6417 - loss: 0.6222 - val_accuracy: 0.4881 - val_loss: 0.8155\n",
      "Epoch 104/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6534 - loss: 0.6376 - val_accuracy: 0.5356 - val_loss: 0.7746\n",
      "Epoch 105/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6802 - loss: 0.6090 - val_accuracy: 0.5594 - val_loss: 0.8851\n",
      "Epoch 106/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6472 - loss: 0.6315 - val_accuracy: 0.5119 - val_loss: 0.9056\n",
      "Epoch 107/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6253 - loss: 0.6502 - val_accuracy: 0.5198 - val_loss: 0.8462\n",
      "Epoch 108/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6645 - loss: 0.6255 - val_accuracy: 0.5198 - val_loss: 0.9124\n",
      "Epoch 109/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6435 - loss: 0.6295 - val_accuracy: 0.5277 - val_loss: 0.8350\n",
      "Epoch 110/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6419 - loss: 0.6279 - val_accuracy: 0.4749 - val_loss: 0.9555\n",
      "Epoch 111/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6433 - loss: 0.6329 - val_accuracy: 0.4908 - val_loss: 0.8905\n",
      "Epoch 112/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6445 - loss: 0.6342 - val_accuracy: 0.5013 - val_loss: 0.8226\n",
      "Epoch 113/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6713 - loss: 0.5980 - val_accuracy: 0.5013 - val_loss: 0.9902\n",
      "Epoch 114/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6554 - loss: 0.6559 - val_accuracy: 0.5303 - val_loss: 0.8866\n",
      "Epoch 115/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6444 - loss: 0.6357 - val_accuracy: 0.5066 - val_loss: 0.8622\n",
      "Epoch 116/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6656 - loss: 0.6231 - val_accuracy: 0.4960 - val_loss: 0.9175\n",
      "Epoch 117/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6783 - loss: 0.5960 - val_accuracy: 0.5092 - val_loss: 0.9644\n",
      "Epoch 118/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6727 - loss: 0.5998 - val_accuracy: 0.5330 - val_loss: 0.8114\n",
      "Epoch 119/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6799 - loss: 0.5983 - val_accuracy: 0.5172 - val_loss: 0.8287\n",
      "Epoch 120/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6961 - loss: 0.5873 - val_accuracy: 0.4934 - val_loss: 0.8709\n",
      "Epoch 121/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6635 - loss: 0.6103 - val_accuracy: 0.4776 - val_loss: 0.8500\n",
      "Epoch 122/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6560 - loss: 0.6235 - val_accuracy: 0.5119 - val_loss: 0.8689\n",
      "Epoch 123/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6733 - loss: 0.6194 - val_accuracy: 0.5462 - val_loss: 0.7978\n",
      "Epoch 124/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6632 - loss: 0.6031 - val_accuracy: 0.5198 - val_loss: 0.9377\n",
      "Epoch 125/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7131 - loss: 0.5697 - val_accuracy: 0.4828 - val_loss: 0.8349\n",
      "Epoch 126/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6927 - loss: 0.5913 - val_accuracy: 0.4908 - val_loss: 0.9639\n",
      "Epoch 127/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7035 - loss: 0.5783 - val_accuracy: 0.5172 - val_loss: 0.8892\n",
      "Epoch 128/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7036 - loss: 0.5948 - val_accuracy: 0.4802 - val_loss: 0.9224\n",
      "Epoch 129/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6988 - loss: 0.5739 - val_accuracy: 0.4960 - val_loss: 0.9645\n",
      "Epoch 130/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6699 - loss: 0.6061 - val_accuracy: 0.4776 - val_loss: 0.9184\n",
      "Epoch 131/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6943 - loss: 0.5819 - val_accuracy: 0.5066 - val_loss: 0.8303\n",
      "Epoch 132/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6992 - loss: 0.5615 - val_accuracy: 0.5013 - val_loss: 0.9059\n",
      "Epoch 133/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6880 - loss: 0.6014 - val_accuracy: 0.4960 - val_loss: 0.9038\n",
      "Epoch 134/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6846 - loss: 0.6035 - val_accuracy: 0.4987 - val_loss: 1.0005\n",
      "Epoch 135/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6828 - loss: 0.5889 - val_accuracy: 0.4960 - val_loss: 0.9446\n",
      "Epoch 136/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6776 - loss: 0.6102 - val_accuracy: 0.4908 - val_loss: 0.9341\n",
      "Epoch 137/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7117 - loss: 0.5671 - val_accuracy: 0.5277 - val_loss: 0.8861\n",
      "Epoch 138/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6712 - loss: 0.5907 - val_accuracy: 0.5066 - val_loss: 0.9692\n",
      "Epoch 139/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7096 - loss: 0.5687 - val_accuracy: 0.5198 - val_loss: 0.8659\n",
      "Epoch 140/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6929 - loss: 0.5808 - val_accuracy: 0.5330 - val_loss: 0.9257\n",
      "Epoch 141/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7165 - loss: 0.5596 - val_accuracy: 0.4934 - val_loss: 0.9997\n",
      "Epoch 142/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6994 - loss: 0.5711 - val_accuracy: 0.4960 - val_loss: 0.8779\n",
      "Epoch 143/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7131 - loss: 0.5601 - val_accuracy: 0.4908 - val_loss: 0.9659\n",
      "Epoch 144/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6986 - loss: 0.5857 - val_accuracy: 0.5092 - val_loss: 0.8730\n",
      "Epoch 145/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7077 - loss: 0.5714 - val_accuracy: 0.5356 - val_loss: 0.8745\n",
      "Epoch 146/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7281 - loss: 0.5351 - val_accuracy: 0.4723 - val_loss: 0.9683\n",
      "Epoch 147/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7390 - loss: 0.5430 - val_accuracy: 0.5251 - val_loss: 0.8790\n",
      "Epoch 148/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7111 - loss: 0.5614 - val_accuracy: 0.5013 - val_loss: 0.8623\n",
      "Epoch 149/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7070 - loss: 0.5418 - val_accuracy: 0.5119 - val_loss: 0.8952\n",
      "Epoch 150/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7120 - loss: 0.5492 - val_accuracy: 0.5277 - val_loss: 0.9443\n",
      "Epoch 151/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7152 - loss: 0.5606 - val_accuracy: 0.5013 - val_loss: 0.9986\n",
      "Epoch 152/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7118 - loss: 0.5610 - val_accuracy: 0.5040 - val_loss: 0.8818\n",
      "Epoch 153/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7399 - loss: 0.5265 - val_accuracy: 0.4934 - val_loss: 0.9716\n",
      "Epoch 154/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7469 - loss: 0.5255 - val_accuracy: 0.4960 - val_loss: 0.9639\n",
      "Epoch 155/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7455 - loss: 0.5276 - val_accuracy: 0.4881 - val_loss: 1.1639\n",
      "Epoch 156/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7387 - loss: 0.5249 - val_accuracy: 0.5040 - val_loss: 1.0006\n",
      "Epoch 157/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7256 - loss: 0.5528 - val_accuracy: 0.4960 - val_loss: 0.9909\n",
      "Epoch 158/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7289 - loss: 0.5179 - val_accuracy: 0.4802 - val_loss: 1.0450\n",
      "Epoch 159/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7123 - loss: 0.5426 - val_accuracy: 0.4802 - val_loss: 1.0151\n",
      "Epoch 160/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7340 - loss: 0.5177 - val_accuracy: 0.5198 - val_loss: 1.0574\n",
      "Epoch 161/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7190 - loss: 0.5515 - val_accuracy: 0.5040 - val_loss: 0.9086\n",
      "Epoch 162/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7310 - loss: 0.5180 - val_accuracy: 0.5198 - val_loss: 0.9489\n",
      "Epoch 163/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7327 - loss: 0.5128 - val_accuracy: 0.5119 - val_loss: 0.9459\n",
      "Epoch 164/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7669 - loss: 0.5003 - val_accuracy: 0.4855 - val_loss: 1.0342\n",
      "Epoch 165/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7429 - loss: 0.4985 - val_accuracy: 0.4934 - val_loss: 0.9840\n",
      "Epoch 166/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7560 - loss: 0.5123 - val_accuracy: 0.5172 - val_loss: 0.9657\n",
      "Epoch 167/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7531 - loss: 0.4881 - val_accuracy: 0.5172 - val_loss: 1.0373\n",
      "Epoch 168/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7420 - loss: 0.5334 - val_accuracy: 0.4828 - val_loss: 1.0559\n",
      "Epoch 169/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7396 - loss: 0.5195 - val_accuracy: 0.4987 - val_loss: 1.1018\n",
      "Epoch 170/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7546 - loss: 0.4849 - val_accuracy: 0.4828 - val_loss: 1.1156\n",
      "Epoch 171/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7642 - loss: 0.5014 - val_accuracy: 0.5224 - val_loss: 1.1304\n",
      "Epoch 172/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7750 - loss: 0.4814 - val_accuracy: 0.5198 - val_loss: 0.9993\n",
      "Epoch 173/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7345 - loss: 0.5066 - val_accuracy: 0.5172 - val_loss: 1.0171\n",
      "Epoch 174/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7709 - loss: 0.4779 - val_accuracy: 0.5066 - val_loss: 1.1655\n",
      "Epoch 175/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7211 - loss: 0.5207 - val_accuracy: 0.4960 - val_loss: 1.0362\n",
      "Epoch 176/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7524 - loss: 0.4780 - val_accuracy: 0.5172 - val_loss: 0.9499\n",
      "Epoch 177/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7896 - loss: 0.4386 - val_accuracy: 0.5224 - val_loss: 0.9918\n",
      "Epoch 178/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7575 - loss: 0.4900 - val_accuracy: 0.4855 - val_loss: 1.0852\n",
      "Epoch 179/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7638 - loss: 0.4755 - val_accuracy: 0.5198 - val_loss: 1.0000\n",
      "Epoch 180/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7621 - loss: 0.4947 - val_accuracy: 0.4908 - val_loss: 1.0216\n",
      "Epoch 181/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7568 - loss: 0.4760 - val_accuracy: 0.5198 - val_loss: 1.0218\n",
      "Epoch 182/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7554 - loss: 0.4841 - val_accuracy: 0.5383 - val_loss: 1.0592\n",
      "Epoch 183/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7558 - loss: 0.4947 - val_accuracy: 0.5251 - val_loss: 1.1038\n",
      "Epoch 184/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7800 - loss: 0.4528 - val_accuracy: 0.4960 - val_loss: 1.1398\n",
      "Epoch 185/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7679 - loss: 0.4931 - val_accuracy: 0.5383 - val_loss: 1.0046\n",
      "Epoch 186/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7734 - loss: 0.4906 - val_accuracy: 0.4908 - val_loss: 1.1399\n",
      "Epoch 187/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7682 - loss: 0.4723 - val_accuracy: 0.5224 - val_loss: 1.0010\n",
      "Epoch 188/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7824 - loss: 0.4516 - val_accuracy: 0.4855 - val_loss: 1.0776\n",
      "Epoch 189/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7718 - loss: 0.4772 - val_accuracy: 0.5224 - val_loss: 0.9881\n",
      "Epoch 190/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7798 - loss: 0.4438 - val_accuracy: 0.5172 - val_loss: 1.2156\n",
      "Epoch 191/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7700 - loss: 0.4741 - val_accuracy: 0.4644 - val_loss: 1.0825\n",
      "Epoch 192/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7811 - loss: 0.4616 - val_accuracy: 0.5013 - val_loss: 1.0686\n",
      "Epoch 193/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7923 - loss: 0.4423 - val_accuracy: 0.4934 - val_loss: 1.2083\n",
      "Epoch 194/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7931 - loss: 0.4415 - val_accuracy: 0.5013 - val_loss: 1.0914\n",
      "Epoch 195/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8031 - loss: 0.4053 - val_accuracy: 0.5330 - val_loss: 1.1638\n",
      "Epoch 196/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7709 - loss: 0.4486 - val_accuracy: 0.5198 - val_loss: 1.2115\n",
      "Epoch 197/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7781 - loss: 0.4455 - val_accuracy: 0.5013 - val_loss: 1.1185\n",
      "Epoch 198/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8053 - loss: 0.4392 - val_accuracy: 0.4908 - val_loss: 1.1114\n",
      "Epoch 199/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7973 - loss: 0.4260 - val_accuracy: 0.5224 - val_loss: 1.1366\n",
      "Epoch 200/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7899 - loss: 0.4336 - val_accuracy: 0.4908 - val_loss: 1.2665\n",
      "Epoch 201/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7965 - loss: 0.4289 - val_accuracy: 0.5145 - val_loss: 1.1864\n",
      "Epoch 202/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7950 - loss: 0.4440 - val_accuracy: 0.5303 - val_loss: 1.1115\n",
      "Epoch 203/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7910 - loss: 0.4378 - val_accuracy: 0.5383 - val_loss: 1.1635\n",
      "Epoch 204/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8121 - loss: 0.4122 - val_accuracy: 0.4855 - val_loss: 1.1762\n",
      "Epoch 205/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7838 - loss: 0.4460 - val_accuracy: 0.5013 - val_loss: 1.1895\n",
      "Epoch 206/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7835 - loss: 0.4356 - val_accuracy: 0.5172 - val_loss: 1.1902\n",
      "Epoch 207/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8228 - loss: 0.4042 - val_accuracy: 0.5119 - val_loss: 1.1271\n",
      "Epoch 208/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7886 - loss: 0.4249 - val_accuracy: 0.5145 - val_loss: 1.2130\n",
      "Epoch 209/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8020 - loss: 0.4239 - val_accuracy: 0.5092 - val_loss: 1.2499\n",
      "Epoch 210/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8024 - loss: 0.4058 - val_accuracy: 0.5224 - val_loss: 1.2460\n",
      "Epoch 211/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8076 - loss: 0.4118 - val_accuracy: 0.5330 - val_loss: 1.1625\n",
      "Epoch 212/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8212 - loss: 0.3935 - val_accuracy: 0.5198 - val_loss: 1.1573\n",
      "Epoch 213/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8062 - loss: 0.4105 - val_accuracy: 0.4934 - val_loss: 1.2425\n",
      "Epoch 214/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8322 - loss: 0.3771 - val_accuracy: 0.5224 - val_loss: 1.3192\n",
      "Epoch 215/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7870 - loss: 0.4095 - val_accuracy: 0.5383 - val_loss: 1.3829\n",
      "Epoch 216/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8196 - loss: 0.4020 - val_accuracy: 0.5013 - val_loss: 1.2051\n",
      "Epoch 217/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8118 - loss: 0.3870 - val_accuracy: 0.5066 - val_loss: 1.3165\n",
      "Epoch 218/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7942 - loss: 0.4187 - val_accuracy: 0.4828 - val_loss: 1.3046\n",
      "Epoch 219/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8306 - loss: 0.3551 - val_accuracy: 0.5040 - val_loss: 1.2444\n",
      "Epoch 220/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7880 - loss: 0.4162 - val_accuracy: 0.4987 - val_loss: 1.2345\n",
      "Epoch 221/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8298 - loss: 0.3917 - val_accuracy: 0.4987 - val_loss: 1.1896\n",
      "Epoch 222/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8137 - loss: 0.3980 - val_accuracy: 0.5145 - val_loss: 1.2233\n",
      "Epoch 223/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8313 - loss: 0.3574 - val_accuracy: 0.4802 - val_loss: 1.1977\n",
      "Epoch 224/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8194 - loss: 0.3991 - val_accuracy: 0.5145 - val_loss: 1.2557\n",
      "Epoch 225/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8264 - loss: 0.3880 - val_accuracy: 0.4855 - val_loss: 1.2138\n",
      "Epoch 226/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8138 - loss: 0.3847 - val_accuracy: 0.4670 - val_loss: 1.2922\n",
      "Epoch 227/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8061 - loss: 0.3884 - val_accuracy: 0.4802 - val_loss: 1.3012\n",
      "Epoch 228/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8136 - loss: 0.3903 - val_accuracy: 0.5013 - val_loss: 1.8570\n",
      "Epoch 229/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7962 - loss: 0.4404 - val_accuracy: 0.5013 - val_loss: 1.5917\n",
      "Epoch 230/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8052 - loss: 0.4254 - val_accuracy: 0.4881 - val_loss: 1.1944\n",
      "Epoch 231/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8036 - loss: 0.4214 - val_accuracy: 0.5172 - val_loss: 1.1261\n",
      "Epoch 232/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7952 - loss: 0.4382 - val_accuracy: 0.5013 - val_loss: 1.1891\n",
      "Epoch 233/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8193 - loss: 0.3932 - val_accuracy: 0.4828 - val_loss: 1.1698\n",
      "Epoch 234/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8015 - loss: 0.4045 - val_accuracy: 0.5066 - val_loss: 1.1387\n",
      "Epoch 235/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8055 - loss: 0.3986 - val_accuracy: 0.5303 - val_loss: 1.1357\n",
      "Epoch 236/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8074 - loss: 0.4190 - val_accuracy: 0.5198 - val_loss: 1.1760\n",
      "Epoch 237/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8100 - loss: 0.3972 - val_accuracy: 0.5040 - val_loss: 1.2900\n",
      "Epoch 238/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7965 - loss: 0.4220 - val_accuracy: 0.5066 - val_loss: 1.1363\n",
      "Epoch 239/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7889 - loss: 0.4198 - val_accuracy: 0.5330 - val_loss: 1.1477\n",
      "Epoch 240/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8230 - loss: 0.3834 - val_accuracy: 0.5013 - val_loss: 1.2499\n",
      "Epoch 241/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8143 - loss: 0.3929 - val_accuracy: 0.5040 - val_loss: 1.2403\n",
      "Epoch 242/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8159 - loss: 0.3979 - val_accuracy: 0.4960 - val_loss: 1.3776\n",
      "Epoch 243/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8238 - loss: 0.4056 - val_accuracy: 0.5013 - val_loss: 1.3005\n",
      "Epoch 244/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7850 - loss: 0.4430 - val_accuracy: 0.5013 - val_loss: 1.2163\n",
      "Epoch 245/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8389 - loss: 0.3322 - val_accuracy: 0.4934 - val_loss: 1.2752\n",
      "Epoch 246/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8286 - loss: 0.3625 - val_accuracy: 0.4881 - val_loss: 1.2218\n",
      "Epoch 247/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8214 - loss: 0.3808 - val_accuracy: 0.5040 - val_loss: 1.2678\n",
      "Epoch 248/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8311 - loss: 0.3745 - val_accuracy: 0.5145 - val_loss: 1.3474\n",
      "Epoch 249/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8296 - loss: 0.3868 - val_accuracy: 0.4644 - val_loss: 1.3677\n",
      "Epoch 250/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 0.3851 - val_accuracy: 0.4908 - val_loss: 1.3262\n",
      "Epoch 251/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8111 - loss: 0.3877 - val_accuracy: 0.4934 - val_loss: 1.3302\n",
      "Epoch 252/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.3528 - val_accuracy: 0.5013 - val_loss: 1.5634\n",
      "Epoch 253/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8342 - loss: 0.3651 - val_accuracy: 0.4749 - val_loss: 1.3374\n",
      "Epoch 254/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8384 - loss: 0.3790 - val_accuracy: 0.4908 - val_loss: 1.2875\n",
      "Epoch 255/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8358 - loss: 0.3604 - val_accuracy: 0.5066 - val_loss: 1.3623\n",
      "Epoch 256/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8309 - loss: 0.3519 - val_accuracy: 0.4987 - val_loss: 1.4964\n",
      "Epoch 257/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8286 - loss: 0.3783 - val_accuracy: 0.4855 - val_loss: 1.3644\n",
      "Epoch 258/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8535 - loss: 0.3314 - val_accuracy: 0.4987 - val_loss: 1.3227\n",
      "Epoch 259/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8543 - loss: 0.3533 - val_accuracy: 0.4908 - val_loss: 1.3291\n",
      "Epoch 260/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8372 - loss: 0.3851 - val_accuracy: 0.4934 - val_loss: 1.2530\n",
      "Epoch 261/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.3369 - val_accuracy: 0.5013 - val_loss: 1.2653\n",
      "Epoch 262/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8633 - loss: 0.3190 - val_accuracy: 0.5013 - val_loss: 1.4272\n",
      "Epoch 263/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8439 - loss: 0.3549 - val_accuracy: 0.4723 - val_loss: 1.3270\n",
      "Epoch 264/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8354 - loss: 0.3671 - val_accuracy: 0.5040 - val_loss: 1.3146\n",
      "Epoch 265/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8188 - loss: 0.3868 - val_accuracy: 0.4802 - val_loss: 1.1637\n",
      "Epoch 266/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8457 - loss: 0.3386 - val_accuracy: 0.5251 - val_loss: 1.2445\n",
      "Epoch 267/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8338 - loss: 0.3685 - val_accuracy: 0.5040 - val_loss: 1.3131\n",
      "Epoch 268/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8389 - loss: 0.3578 - val_accuracy: 0.4723 - val_loss: 1.5179\n",
      "Epoch 269/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8305 - loss: 0.3707 - val_accuracy: 0.4855 - val_loss: 1.3248\n",
      "Epoch 270/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8336 - loss: 0.3701 - val_accuracy: 0.4987 - val_loss: 1.3996\n",
      "Epoch 271/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8628 - loss: 0.3400 - val_accuracy: 0.5251 - val_loss: 1.4036\n",
      "Epoch 272/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8400 - loss: 0.3380 - val_accuracy: 0.5119 - val_loss: 1.3649\n",
      "Epoch 273/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8135 - loss: 0.4192 - val_accuracy: 0.5251 - val_loss: 1.2071\n",
      "Epoch 274/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8582 - loss: 0.3343 - val_accuracy: 0.5488 - val_loss: 1.2152\n",
      "Epoch 275/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8267 - loss: 0.3972 - val_accuracy: 0.5066 - val_loss: 1.3209\n",
      "Epoch 276/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8489 - loss: 0.3480 - val_accuracy: 0.4960 - val_loss: 1.3982\n",
      "Epoch 277/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8349 - loss: 0.3693 - val_accuracy: 0.4987 - val_loss: 1.5821\n",
      "Epoch 278/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8368 - loss: 0.3568 - val_accuracy: 0.4828 - val_loss: 1.4969\n",
      "Epoch 279/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8439 - loss: 0.3466 - val_accuracy: 0.4881 - val_loss: 1.4016\n",
      "Epoch 280/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8443 - loss: 0.3390 - val_accuracy: 0.5066 - val_loss: 1.3733\n",
      "Epoch 281/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8490 - loss: 0.3165 - val_accuracy: 0.4934 - val_loss: 1.3566\n",
      "Epoch 282/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8579 - loss: 0.3477 - val_accuracy: 0.4908 - val_loss: 1.2842\n",
      "Epoch 283/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8493 - loss: 0.3630 - val_accuracy: 0.4802 - val_loss: 1.3039\n",
      "Epoch 284/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8565 - loss: 0.3378 - val_accuracy: 0.5145 - val_loss: 1.3686\n",
      "Epoch 285/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8571 - loss: 0.3408 - val_accuracy: 0.5356 - val_loss: 1.4024\n",
      "Epoch 286/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8457 - loss: 0.3463 - val_accuracy: 0.5435 - val_loss: 1.2789\n",
      "Epoch 287/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8493 - loss: 0.3559 - val_accuracy: 0.4828 - val_loss: 1.4043\n",
      "Epoch 288/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8525 - loss: 0.3395 - val_accuracy: 0.5251 - val_loss: 1.2946\n",
      "Epoch 289/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8519 - loss: 0.3412 - val_accuracy: 0.5066 - val_loss: 1.3501\n",
      "Epoch 290/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8568 - loss: 0.3140 - val_accuracy: 0.5356 - val_loss: 1.4512\n",
      "Epoch 291/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8461 - loss: 0.3443 - val_accuracy: 0.5251 - val_loss: 1.3619\n",
      "Epoch 292/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8364 - loss: 0.3579 - val_accuracy: 0.5330 - val_loss: 1.4590\n",
      "Epoch 293/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8699 - loss: 0.3143 - val_accuracy: 0.4723 - val_loss: 1.4112\n",
      "Epoch 294/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8516 - loss: 0.3443 - val_accuracy: 0.5013 - val_loss: 1.4587\n",
      "Epoch 295/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8625 - loss: 0.3260 - val_accuracy: 0.4723 - val_loss: 1.5364\n",
      "Epoch 296/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8563 - loss: 0.3196 - val_accuracy: 0.5145 - val_loss: 1.3409\n",
      "Epoch 297/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8556 - loss: 0.3277 - val_accuracy: 0.5145 - val_loss: 1.3556\n",
      "Epoch 298/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8391 - loss: 0.3497 - val_accuracy: 0.5040 - val_loss: 1.5922\n",
      "Epoch 299/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8585 - loss: 0.3140 - val_accuracy: 0.5198 - val_loss: 1.3794\n",
      "Epoch 300/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8603 - loss: 0.3025 - val_accuracy: 0.5040 - val_loss: 1.3376\n",
      "Epoch 301/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8586 - loss: 0.3354 - val_accuracy: 0.4987 - val_loss: 1.4607\n",
      "Epoch 302/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8288 - loss: 0.3878 - val_accuracy: 0.5145 - val_loss: 1.4358\n",
      "Epoch 303/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8724 - loss: 0.3051 - val_accuracy: 0.5145 - val_loss: 1.3998\n",
      "Epoch 304/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8650 - loss: 0.3307 - val_accuracy: 0.5092 - val_loss: 1.4407\n",
      "Epoch 305/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8625 - loss: 0.3055 - val_accuracy: 0.5119 - val_loss: 1.4867\n",
      "Epoch 306/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8437 - loss: 0.3469 - val_accuracy: 0.5462 - val_loss: 1.3817\n",
      "Epoch 307/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8569 - loss: 0.3176 - val_accuracy: 0.4881 - val_loss: 1.5226\n",
      "Epoch 308/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8733 - loss: 0.3134 - val_accuracy: 0.5224 - val_loss: 1.4236\n",
      "Epoch 309/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8742 - loss: 0.3140 - val_accuracy: 0.4802 - val_loss: 1.5304\n",
      "Epoch 310/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8549 - loss: 0.3379 - val_accuracy: 0.4802 - val_loss: 1.4514\n",
      "Epoch 311/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8290 - loss: 0.3657 - val_accuracy: 0.4776 - val_loss: 1.4735\n",
      "Epoch 312/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8494 - loss: 0.3234 - val_accuracy: 0.4723 - val_loss: 1.5040\n",
      "Epoch 313/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8470 - loss: 0.3357 - val_accuracy: 0.4908 - val_loss: 1.3172\n",
      "Epoch 314/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8466 - loss: 0.3448 - val_accuracy: 0.4908 - val_loss: 1.3269\n",
      "Epoch 315/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8526 - loss: 0.3470 - val_accuracy: 0.4881 - val_loss: 1.3421\n",
      "Epoch 316/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8364 - loss: 0.3567 - val_accuracy: 0.5013 - val_loss: 1.4805\n",
      "Epoch 317/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8449 - loss: 0.3510 - val_accuracy: 0.4749 - val_loss: 1.3091\n",
      "Epoch 318/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8637 - loss: 0.3134 - val_accuracy: 0.4855 - val_loss: 1.3989\n",
      "Epoch 319/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8519 - loss: 0.3302 - val_accuracy: 0.4881 - val_loss: 1.3839\n",
      "Epoch 320/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8560 - loss: 0.3389 - val_accuracy: 0.4908 - val_loss: 1.4547\n",
      "Epoch 321/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8347 - loss: 0.3785 - val_accuracy: 0.5066 - val_loss: 1.4228\n",
      "Epoch 322/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8379 - loss: 0.3758 - val_accuracy: 0.5092 - val_loss: 1.3928\n",
      "Epoch 323/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8310 - loss: 0.3675 - val_accuracy: 0.5224 - val_loss: 1.2838\n",
      "Epoch 324/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8539 - loss: 0.3391 - val_accuracy: 0.5066 - val_loss: 1.3899\n",
      "Epoch 325/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8462 - loss: 0.3403 - val_accuracy: 0.4881 - val_loss: 1.3540\n",
      "Epoch 326/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8390 - loss: 0.3566 - val_accuracy: 0.5066 - val_loss: 1.4001\n",
      "Epoch 327/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8574 - loss: 0.2862 - val_accuracy: 0.5066 - val_loss: 1.4765\n",
      "Epoch 328/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.3277 - val_accuracy: 0.4855 - val_loss: 1.4976\n",
      "Epoch 329/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8569 - loss: 0.3361 - val_accuracy: 0.4881 - val_loss: 1.4968\n",
      "Epoch 330/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8625 - loss: 0.3091 - val_accuracy: 0.5013 - val_loss: 1.5058\n",
      "Epoch 331/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8487 - loss: 0.3338 - val_accuracy: 0.5198 - val_loss: 1.4039\n",
      "Epoch 332/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8676 - loss: 0.3156 - val_accuracy: 0.5303 - val_loss: 1.3167\n",
      "Epoch 333/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8569 - loss: 0.3176 - val_accuracy: 0.5040 - val_loss: 1.3137\n",
      "Epoch 334/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8503 - loss: 0.3235 - val_accuracy: 0.5145 - val_loss: 1.4185\n",
      "Epoch 335/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8534 - loss: 0.3457 - val_accuracy: 0.4670 - val_loss: 1.5978\n",
      "Epoch 336/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8687 - loss: 0.2961 - val_accuracy: 0.5013 - val_loss: 1.5442\n",
      "Epoch 337/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8580 - loss: 0.3201 - val_accuracy: 0.5119 - val_loss: 1.5535\n",
      "Epoch 338/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8641 - loss: 0.3098 - val_accuracy: 0.4908 - val_loss: 1.4620\n",
      "Epoch 339/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8619 - loss: 0.3101 - val_accuracy: 0.5013 - val_loss: 1.5185\n",
      "Epoch 340/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8593 - loss: 0.3326 - val_accuracy: 0.4934 - val_loss: 1.5545\n",
      "Epoch 341/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8633 - loss: 0.3161 - val_accuracy: 0.4828 - val_loss: 1.3788\n",
      "Epoch 342/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8515 - loss: 0.3151 - val_accuracy: 0.5013 - val_loss: 1.4371\n",
      "Epoch 343/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8497 - loss: 0.3057 - val_accuracy: 0.5198 - val_loss: 1.4789\n",
      "Epoch 344/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8740 - loss: 0.2970 - val_accuracy: 0.5277 - val_loss: 1.5659\n",
      "Epoch 345/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8683 - loss: 0.2988 - val_accuracy: 0.5092 - val_loss: 1.4999\n",
      "Epoch 346/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8602 - loss: 0.3202 - val_accuracy: 0.5224 - val_loss: 1.4987\n",
      "Epoch 347/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8736 - loss: 0.3085 - val_accuracy: 0.4617 - val_loss: 1.4858\n",
      "Epoch 348/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8598 - loss: 0.3171 - val_accuracy: 0.5066 - val_loss: 1.5139\n",
      "Epoch 349/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8998 - loss: 0.2454 - val_accuracy: 0.4855 - val_loss: 1.4331\n",
      "Epoch 350/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8866 - loss: 0.2770 - val_accuracy: 0.4960 - val_loss: 1.5648\n",
      "Epoch 351/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8734 - loss: 0.2636 - val_accuracy: 0.4776 - val_loss: 1.5177\n",
      "Epoch 352/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8553 - loss: 0.3160 - val_accuracy: 0.4565 - val_loss: 1.7469\n",
      "Epoch 353/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8717 - loss: 0.3128 - val_accuracy: 0.4855 - val_loss: 1.5570\n",
      "Epoch 354/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8605 - loss: 0.3214 - val_accuracy: 0.4987 - val_loss: 1.5234\n",
      "Epoch 355/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8701 - loss: 0.2940 - val_accuracy: 0.4934 - val_loss: 1.4781\n",
      "Epoch 356/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8512 - loss: 0.3416 - val_accuracy: 0.5013 - val_loss: 1.4565\n",
      "Epoch 357/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8683 - loss: 0.3184 - val_accuracy: 0.5409 - val_loss: 1.2539\n",
      "Epoch 358/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8620 - loss: 0.3037 - val_accuracy: 0.5303 - val_loss: 1.3698\n",
      "Epoch 359/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8633 - loss: 0.2997 - val_accuracy: 0.4908 - val_loss: 1.3968\n",
      "Epoch 360/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8873 - loss: 0.2757 - val_accuracy: 0.5145 - val_loss: 1.5212\n",
      "Epoch 361/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8627 - loss: 0.3329 - val_accuracy: 0.5277 - val_loss: 1.3517\n",
      "Epoch 362/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8823 - loss: 0.2979 - val_accuracy: 0.4987 - val_loss: 1.4994\n",
      "Epoch 363/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8528 - loss: 0.3356 - val_accuracy: 0.5198 - val_loss: 1.3746\n",
      "Epoch 364/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8559 - loss: 0.3123 - val_accuracy: 0.5119 - val_loss: 1.3827\n",
      "Epoch 365/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8553 - loss: 0.3334 - val_accuracy: 0.5383 - val_loss: 1.3262\n",
      "Epoch 366/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8500 - loss: 0.3403 - val_accuracy: 0.5172 - val_loss: 1.3678\n",
      "Epoch 367/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8589 - loss: 0.3179 - val_accuracy: 0.5303 - val_loss: 1.3927\n",
      "Epoch 368/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8697 - loss: 0.3040 - val_accuracy: 0.5066 - val_loss: 1.3284\n",
      "Epoch 369/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8771 - loss: 0.2955 - val_accuracy: 0.4987 - val_loss: 1.3266\n",
      "Epoch 370/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9043 - loss: 0.2465 - val_accuracy: 0.5172 - val_loss: 1.3609\n",
      "Epoch 371/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8400 - loss: 0.3655 - val_accuracy: 0.5040 - val_loss: 1.3798\n",
      "Epoch 372/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8683 - loss: 0.3072 - val_accuracy: 0.4776 - val_loss: 1.4532\n",
      "Epoch 373/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8690 - loss: 0.3218 - val_accuracy: 0.4934 - val_loss: 1.4130\n",
      "Epoch 374/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8453 - loss: 0.3487 - val_accuracy: 0.4908 - val_loss: 1.3324\n",
      "Epoch 375/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8670 - loss: 0.3101 - val_accuracy: 0.5224 - val_loss: 1.3144\n",
      "Epoch 376/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8497 - loss: 0.3595 - val_accuracy: 0.5092 - val_loss: 1.3261\n",
      "Epoch 377/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8617 - loss: 0.2991 - val_accuracy: 0.4881 - val_loss: 1.4072\n",
      "Epoch 378/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8816 - loss: 0.3003 - val_accuracy: 0.5119 - val_loss: 1.4527\n",
      "Epoch 379/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8721 - loss: 0.2812 - val_accuracy: 0.5040 - val_loss: 1.4355\n",
      "Epoch 380/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8765 - loss: 0.2817 - val_accuracy: 0.4934 - val_loss: 1.4185\n",
      "Epoch 381/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8624 - loss: 0.3023 - val_accuracy: 0.4749 - val_loss: 1.4304\n",
      "Epoch 382/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8572 - loss: 0.3108 - val_accuracy: 0.5040 - val_loss: 1.5389\n",
      "Epoch 383/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8806 - loss: 0.2711 - val_accuracy: 0.5145 - val_loss: 1.6202\n",
      "Epoch 384/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8792 - loss: 0.2949 - val_accuracy: 0.5356 - val_loss: 1.5294\n",
      "Epoch 385/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8630 - loss: 0.3019 - val_accuracy: 0.5040 - val_loss: 1.5871\n",
      "Epoch 386/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8821 - loss: 0.2790 - val_accuracy: 0.4881 - val_loss: 1.6162\n",
      "Epoch 387/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8818 - loss: 0.2895 - val_accuracy: 0.4749 - val_loss: 1.5619\n",
      "Epoch 388/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8604 - loss: 0.3146 - val_accuracy: 0.4987 - val_loss: 1.4894\n",
      "Epoch 389/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8809 - loss: 0.2781 - val_accuracy: 0.4908 - val_loss: 1.4251\n",
      "Epoch 390/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8832 - loss: 0.2767 - val_accuracy: 0.5356 - val_loss: 1.4208\n",
      "Epoch 391/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8760 - loss: 0.2659 - val_accuracy: 0.4908 - val_loss: 1.6644\n",
      "Epoch 392/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8662 - loss: 0.2902 - val_accuracy: 0.5013 - val_loss: 1.5580\n",
      "Epoch 393/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8852 - loss: 0.2953 - val_accuracy: 0.5119 - val_loss: 1.5214\n",
      "Epoch 394/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8317 - loss: 0.3871 - val_accuracy: 0.5145 - val_loss: 1.5457\n",
      "Epoch 395/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8318 - loss: 0.3690 - val_accuracy: 0.5330 - val_loss: 1.3530\n",
      "Epoch 396/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8473 - loss: 0.3466 - val_accuracy: 0.5066 - val_loss: 1.3718\n",
      "Epoch 397/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8557 - loss: 0.3315 - val_accuracy: 0.4591 - val_loss: 1.6135\n",
      "Epoch 398/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8379 - loss: 0.3625 - val_accuracy: 0.4828 - val_loss: 1.4279\n",
      "Epoch 399/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8719 - loss: 0.3192 - val_accuracy: 0.4934 - val_loss: 1.3843\n",
      "Epoch 400/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8400 - loss: 0.3412 - val_accuracy: 0.4934 - val_loss: 1.3212\n",
      "Epoch 401/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8616 - loss: 0.3091 - val_accuracy: 0.4908 - val_loss: 1.3530\n",
      "Epoch 402/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8812 - loss: 0.2705 - val_accuracy: 0.4960 - val_loss: 1.4972\n",
      "Epoch 403/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8745 - loss: 0.2897 - val_accuracy: 0.5013 - val_loss: 1.4308\n",
      "Epoch 404/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8689 - loss: 0.2847 - val_accuracy: 0.5066 - val_loss: 1.4315\n",
      "Epoch 405/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8754 - loss: 0.3006 - val_accuracy: 0.5092 - val_loss: 1.4818\n",
      "Epoch 406/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8809 - loss: 0.2886 - val_accuracy: 0.5303 - val_loss: 1.3988\n",
      "Epoch 407/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8841 - loss: 0.2558 - val_accuracy: 0.5330 - val_loss: 1.4222\n",
      "Epoch 408/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8689 - loss: 0.2983 - val_accuracy: 0.5092 - val_loss: 1.4815\n",
      "Epoch 409/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8937 - loss: 0.2719 - val_accuracy: 0.4855 - val_loss: 1.5823\n",
      "Epoch 410/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8507 - loss: 0.3360 - val_accuracy: 0.4934 - val_loss: 1.5059\n",
      "Epoch 411/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8821 - loss: 0.2695 - val_accuracy: 0.4960 - val_loss: 1.4508\n",
      "Epoch 412/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8854 - loss: 0.2925 - val_accuracy: 0.5066 - val_loss: 1.4752\n",
      "Epoch 413/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8958 - loss: 0.2712 - val_accuracy: 0.5224 - val_loss: 1.4636\n",
      "Epoch 414/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8979 - loss: 0.2450 - val_accuracy: 0.5119 - val_loss: 1.5944\n",
      "Epoch 415/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8768 - loss: 0.2879 - val_accuracy: 0.5303 - val_loss: 1.5848\n",
      "Epoch 416/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8710 - loss: 0.3162 - val_accuracy: 0.5145 - val_loss: 1.4857\n",
      "Epoch 417/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8653 - loss: 0.3138 - val_accuracy: 0.5303 - val_loss: 1.4672\n",
      "Epoch 418/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8594 - loss: 0.3116 - val_accuracy: 0.4749 - val_loss: 1.6614\n",
      "Epoch 419/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.2882 - val_accuracy: 0.4855 - val_loss: 1.4973\n",
      "Epoch 420/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8559 - loss: 0.3106 - val_accuracy: 0.5040 - val_loss: 1.5467\n",
      "Epoch 421/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8830 - loss: 0.2640 - val_accuracy: 0.5330 - val_loss: 1.5471\n",
      "Epoch 422/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8796 - loss: 0.2883 - val_accuracy: 0.5013 - val_loss: 1.4476\n",
      "Epoch 423/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.2865 - val_accuracy: 0.5303 - val_loss: 1.4192\n",
      "Epoch 424/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8529 - loss: 0.3407 - val_accuracy: 0.5145 - val_loss: 1.3259\n",
      "Epoch 425/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8648 - loss: 0.3133 - val_accuracy: 0.5013 - val_loss: 1.3235\n",
      "Epoch 426/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8683 - loss: 0.3231 - val_accuracy: 0.5066 - val_loss: 1.4359\n",
      "Epoch 427/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8840 - loss: 0.2537 - val_accuracy: 0.5145 - val_loss: 1.5816\n",
      "Epoch 428/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8761 - loss: 0.2934 - val_accuracy: 0.5224 - val_loss: 1.6048\n",
      "Epoch 429/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8904 - loss: 0.2609 - val_accuracy: 0.5145 - val_loss: 1.4269\n",
      "Epoch 430/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8730 - loss: 0.2826 - val_accuracy: 0.5224 - val_loss: 1.4484\n",
      "Epoch 431/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8800 - loss: 0.2711 - val_accuracy: 0.5145 - val_loss: 1.4152\n",
      "Epoch 432/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8874 - loss: 0.2639 - val_accuracy: 0.5013 - val_loss: 1.4948\n",
      "Epoch 433/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8804 - loss: 0.2641 - val_accuracy: 0.5172 - val_loss: 1.4750\n",
      "Epoch 434/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8795 - loss: 0.2586 - val_accuracy: 0.5119 - val_loss: 1.4561\n",
      "Epoch 435/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8801 - loss: 0.2864 - val_accuracy: 0.4908 - val_loss: 1.5116\n",
      "Epoch 436/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8740 - loss: 0.2671 - val_accuracy: 0.5172 - val_loss: 1.7652\n",
      "Epoch 437/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8772 - loss: 0.2946 - val_accuracy: 0.5092 - val_loss: 1.6937\n",
      "Epoch 438/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9103 - loss: 0.2431 - val_accuracy: 0.5092 - val_loss: 1.6775\n",
      "Epoch 439/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8749 - loss: 0.2742 - val_accuracy: 0.5092 - val_loss: 1.6091\n",
      "Epoch 440/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8832 - loss: 0.2444 - val_accuracy: 0.5092 - val_loss: 1.5284\n",
      "Epoch 441/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9140 - loss: 0.2085 - val_accuracy: 0.5119 - val_loss: 1.5366\n",
      "Epoch 442/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8965 - loss: 0.2422 - val_accuracy: 0.5040 - val_loss: 1.7515\n",
      "Epoch 443/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8733 - loss: 0.2977 - val_accuracy: 0.5303 - val_loss: 1.5517\n",
      "Epoch 444/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8502 - loss: 0.3462 - val_accuracy: 0.4776 - val_loss: 1.4776\n",
      "Epoch 445/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8747 - loss: 0.2850 - val_accuracy: 0.5013 - val_loss: 1.4512\n",
      "Epoch 446/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8854 - loss: 0.2847 - val_accuracy: 0.5303 - val_loss: 1.4320\n",
      "Epoch 447/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8966 - loss: 0.2510 - val_accuracy: 0.5277 - val_loss: 1.4582\n",
      "Epoch 448/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8796 - loss: 0.2951 - val_accuracy: 0.5040 - val_loss: 1.5437\n",
      "Epoch 449/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8920 - loss: 0.2607 - val_accuracy: 0.5198 - val_loss: 1.4675\n",
      "Epoch 450/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8970 - loss: 0.2519 - val_accuracy: 0.5119 - val_loss: 1.6617\n",
      "Epoch 451/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8813 - loss: 0.2658 - val_accuracy: 0.5066 - val_loss: 1.6515\n",
      "Epoch 452/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8773 - loss: 0.2751 - val_accuracy: 0.5330 - val_loss: 1.5803\n",
      "Epoch 453/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8920 - loss: 0.2722 - val_accuracy: 0.4802 - val_loss: 1.7002\n",
      "Epoch 454/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8880 - loss: 0.2546 - val_accuracy: 0.5092 - val_loss: 1.3970\n",
      "Epoch 455/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8705 - loss: 0.2956 - val_accuracy: 0.5040 - val_loss: 1.5414\n",
      "Epoch 456/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8875 - loss: 0.2743 - val_accuracy: 0.5066 - val_loss: 1.5751\n",
      "Epoch 457/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8795 - loss: 0.2803 - val_accuracy: 0.4828 - val_loss: 1.5152\n",
      "Epoch 458/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8826 - loss: 0.2811 - val_accuracy: 0.4723 - val_loss: 1.6274\n",
      "Epoch 459/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8891 - loss: 0.2659 - val_accuracy: 0.4828 - val_loss: 1.5975\n",
      "Epoch 460/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8946 - loss: 0.2613 - val_accuracy: 0.5145 - val_loss: 1.5506\n",
      "Epoch 461/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8887 - loss: 0.2686 - val_accuracy: 0.5224 - val_loss: 1.6075\n",
      "Epoch 462/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8940 - loss: 0.2620 - val_accuracy: 0.4881 - val_loss: 1.8984\n",
      "Epoch 463/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8838 - loss: 0.2510 - val_accuracy: 0.5172 - val_loss: 1.7495\n",
      "Epoch 464/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8658 - loss: 0.3175 - val_accuracy: 0.5172 - val_loss: 1.7077\n",
      "Epoch 465/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8809 - loss: 0.2773 - val_accuracy: 0.5277 - val_loss: 1.5772\n",
      "Epoch 466/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8894 - loss: 0.2610 - val_accuracy: 0.4987 - val_loss: 1.5200\n",
      "Epoch 467/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8851 - loss: 0.2891 - val_accuracy: 0.5013 - val_loss: 1.6283\n",
      "Epoch 468/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8890 - loss: 0.2609 - val_accuracy: 0.5040 - val_loss: 1.5211\n",
      "Epoch 469/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8782 - loss: 0.2939 - val_accuracy: 0.5172 - val_loss: 1.5272\n",
      "Epoch 470/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8854 - loss: 0.2768 - val_accuracy: 0.5092 - val_loss: 1.4303\n",
      "Epoch 471/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8807 - loss: 0.2668 - val_accuracy: 0.5013 - val_loss: 1.4686\n",
      "Epoch 472/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8828 - loss: 0.2754 - val_accuracy: 0.5092 - val_loss: 1.5068\n",
      "Epoch 473/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8955 - loss: 0.2782 - val_accuracy: 0.4987 - val_loss: 1.6619\n",
      "Epoch 474/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8635 - loss: 0.2885 - val_accuracy: 0.5145 - val_loss: 1.4793\n",
      "Epoch 475/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8738 - loss: 0.2971 - val_accuracy: 0.4934 - val_loss: 1.4698\n",
      "Epoch 476/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8938 - loss: 0.2680 - val_accuracy: 0.5040 - val_loss: 1.6108\n",
      "Epoch 477/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8928 - loss: 0.2432 - val_accuracy: 0.5330 - val_loss: 1.5920\n",
      "Epoch 478/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8749 - loss: 0.2741 - val_accuracy: 0.5040 - val_loss: 1.5570\n",
      "Epoch 479/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8852 - loss: 0.2787 - val_accuracy: 0.5462 - val_loss: 1.4863\n",
      "Epoch 480/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8951 - loss: 0.2558 - val_accuracy: 0.5303 - val_loss: 1.6010\n",
      "Epoch 481/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8811 - loss: 0.2895 - val_accuracy: 0.4881 - val_loss: 1.6314\n",
      "Epoch 482/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8979 - loss: 0.2565 - val_accuracy: 0.5040 - val_loss: 1.4964\n",
      "Epoch 483/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8743 - loss: 0.3020 - val_accuracy: 0.5172 - val_loss: 1.5173\n",
      "Epoch 484/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8946 - loss: 0.2423 - val_accuracy: 0.5251 - val_loss: 1.5261\n",
      "Epoch 485/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8858 - loss: 0.2506 - val_accuracy: 0.5198 - val_loss: 1.5364\n",
      "Epoch 486/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8821 - loss: 0.2833 - val_accuracy: 0.5013 - val_loss: 1.6337\n",
      "Epoch 487/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8910 - loss: 0.2431 - val_accuracy: 0.4934 - val_loss: 1.8785\n",
      "Epoch 488/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8972 - loss: 0.2693 - val_accuracy: 0.4934 - val_loss: 1.7245\n",
      "Epoch 489/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8868 - loss: 0.2804 - val_accuracy: 0.4987 - val_loss: 1.7336\n",
      "Epoch 490/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8717 - loss: 0.2854 - val_accuracy: 0.5303 - val_loss: 1.8032\n",
      "Epoch 491/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8592 - loss: 0.3201 - val_accuracy: 0.4591 - val_loss: 1.7538\n",
      "Epoch 492/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8819 - loss: 0.2892 - val_accuracy: 0.5066 - val_loss: 1.5879\n",
      "Epoch 493/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8641 - loss: 0.3060 - val_accuracy: 0.4881 - val_loss: 1.4747\n",
      "Epoch 494/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8951 - loss: 0.2486 - val_accuracy: 0.4934 - val_loss: 1.5076\n",
      "Epoch 495/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8853 - loss: 0.2573 - val_accuracy: 0.5172 - val_loss: 1.3792\n",
      "Epoch 496/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8957 - loss: 0.2638 - val_accuracy: 0.5092 - val_loss: 1.4811\n",
      "Epoch 497/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8899 - loss: 0.2642 - val_accuracy: 0.5013 - val_loss: 1.6078\n",
      "Epoch 498/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8757 - loss: 0.2762 - val_accuracy: 0.5040 - val_loss: 1.5853\n",
      "Epoch 499/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8923 - loss: 0.2623 - val_accuracy: 0.5013 - val_loss: 1.5339\n",
      "Epoch 500/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8800 - loss: 0.2785 - val_accuracy: 0.5330 - val_loss: 1.5565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x149a686d100>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 1.6582 \n",
      "Test accuracy: 0.49682876467704773\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем модель на тестовом наборе\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "            0         1 predict\n",
      "0    0.029042  0.970958      up\n",
      "1    0.018760  0.981240      up\n",
      "2    0.745602  0.254398    down\n",
      "3    0.924239  0.075761    down\n",
      "4    0.335212  0.664788      up\n",
      "..        ...       ...     ...\n",
      "468  0.138390  0.861610      up\n",
      "469  0.705455  0.294545    down\n",
      "470  0.818717  0.181283    down\n",
      "471  0.993473  0.006527    down\n",
      "472  0.590647  0.409353    down\n",
      "\n",
      "[473 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Преобразование чисел в строки с фиксированным количеством десятичных знаков\n",
    "formatted_arr = np.array([[f'{num:.6f}' for num in row] for row in predictions])\n",
    "\n",
    "# Преобразование строк обратно в числа\n",
    "formatted_num_arr = np.array([[float(num) for num in row] for row in formatted_arr])\n",
    "\n",
    "# Преобразуем массив в DataFrame\n",
    "df = pd.DataFrame(formatted_num_arr)\n",
    "\n",
    "# Добавление столбца предсказанной категории\n",
    "df['predict'] = df.apply(lambda x: 'down' if x[0] > x[1] else 'up', axis=1)\n",
    "\n",
    "# Вывод вероятностей для примера из тестовой выборки\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1 predict  real\n",
      "0    0.029042  0.970958      up  down\n",
      "1    0.018760  0.981240      up    up\n",
      "2    0.745602  0.254398    down    up\n",
      "3    0.924239  0.075761    down    up\n",
      "4    0.335212  0.664788      up  down\n",
      "..        ...       ...     ...   ...\n",
      "468  0.138390  0.861610      up  down\n",
      "469  0.705455  0.294545    down    up\n",
      "470  0.818717  0.181283    down    up\n",
      "471  0.993473  0.006527    down  down\n",
      "472  0.590647  0.409353    down    up\n",
      "\n",
      "[473 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем числовые метки обратно в категориальные \n",
    "y_test_lst = [('down' if y[0] == 1.0 else 'up') for y in y_test]\n",
    "\n",
    "# Добавление колонки с реальными напрвлениями баров\n",
    "df['real'] = y_test_lst\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "# Подсчет количества совпадений\n",
    "num_matches = (df['predict'] == df['real']).sum()\n",
    "print(num_matches)\n",
    "\n",
    "# Подсчет количества не совпадений\n",
    "num_no_matches = (df['predict'] != df['real']).sum()\n",
    "print(num_no_matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
