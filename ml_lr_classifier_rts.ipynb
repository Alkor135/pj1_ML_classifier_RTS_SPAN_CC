{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20   21   22   23   24   25   26   27   28   29\n",
      "0     1.000000  0.949765  0.946863  0.890311  0.886746  0.810817  0.768762  0.702327  0.658250  0.519462  0.000000  0.071725  0.156965  0.237875  0.342755  0.385964  0.561642  0.618664  0.710416  0.721658  0.876098  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "1     1.000000  0.999613  0.949249  0.946274  0.888331  0.884700  0.808215  0.764843  0.699029  0.650257  0.510770  0.000000  0.073884  0.163346  0.246354  0.359640  0.402954  0.585638  0.643909  0.737880  0.749382  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
      "2     0.879807  0.815902  0.811820  0.731742  0.685201  0.616099  0.559507  0.401556  0.216736  0.112487  0.000000  0.101511  0.235431  0.280920  0.482243  0.544868  0.668686  0.686063  0.859401  0.888299  1.000000  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n",
      "3     0.948702  0.944897  0.878314  0.873936  0.785999  0.735860  0.661449  0.599869  0.418103  0.218242  0.095601  0.000000  0.115987  0.275745  0.324956  0.549744  0.621755  0.756995  0.775867  0.968883  1.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
      "...        ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "2330  0.822219  0.817015  0.755535  0.735336  0.650304  0.639896  0.520067  0.462909  0.373600  0.256417  0.000000  0.116257  0.460086  0.669357  0.838979  0.902443  0.922113  0.990297  0.998412  0.999162  1.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0\n",
      "2331  0.847162  0.785511  0.765168  0.677490  0.665097  0.548636  0.488985  0.398108  0.276583  0.000000  0.105223  0.454917  0.668029  0.837701  0.901039  0.920272  0.988807  0.996980  0.997690  0.998534  1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "2332  0.842133  0.836920  0.775075  0.754667  0.668182  0.655795  0.544580  0.482600  0.397808  0.280800  0.000000  0.136568  0.462906  0.671479  0.837143  0.902286  0.921579  0.990242  0.998440  0.999153  1.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
      "2333  1.000000  0.990915  0.989586  0.939287  0.934633  0.862841  0.835586  0.716818  0.492577  0.193220  0.000000  0.416796  0.707512  0.808110  0.900731  0.968535  0.981166  0.994460  0.997784  0.998449  0.999114  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Загружаем файл с разделителем ';' в DF\n",
    "df = pd.read_csv(fr'nn_features_and_target.csv', delimiter=';')\n",
    "# df.columns = df.columns.astype(str)\n",
    "df['29'] = df.apply(lambda x: 1.0 if x['28'] == 0.0 else 0.0, axis=1)\n",
    "print(df.to_string(max_rows=8, max_cols=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование в DataSet\n",
    "dataset = df.values  # Dataframe преобразуем в Dataset для Keras\n",
    "dataset = dataset.astype(np.float32)  # Смена типа для корректной работы Keras\n",
    "# Все, что стоит перед запятой, относится к строкам массива, а все, что стоит после запятой,\n",
    "# относится к столбцам массивов.\n",
    "X = dataset[:, 0:28]  # Срез массива по фичам\n",
    "y = dataset[:, 28:30]  # Срез массива по labels\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train_2, y_test_2 = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Преобразования двумерного массива меток в одномерный\n",
    "y_train = np.argmax(y_train_2, axis=1)\n",
    "y_test = np.argmax(y_test_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55851438 0.44148562]\n",
      " [0.51812288 0.48187712]\n",
      " [0.54245284 0.45754716]\n",
      " [0.53196457 0.46803543]\n",
      " [0.47428572 0.52571428]\n",
      " [0.56762034 0.43237966]\n",
      " [0.54520905 0.45479095]\n",
      " [0.53973625 0.46026375]\n",
      " [0.51021139 0.48978861]\n",
      " [0.47642559 0.52357441]\n",
      " [0.56431733 0.43568267]\n",
      " [0.54189219 0.45810781]\n",
      " [0.54850765 0.45149235]\n",
      " [0.49500837 0.50499163]\n",
      " [0.48821419 0.51178581]\n",
      " [0.46292792 0.53707208]\n",
      " [0.53008631 0.46991369]\n",
      " [0.49812753 0.50187247]\n",
      " [0.48312767 0.51687233]\n",
      " [0.49505792 0.50494208]\n",
      " [0.54008417 0.45991583]\n",
      " [0.49503081 0.50496919]\n",
      " [0.51660684 0.48339316]\n",
      " [0.52053087 0.47946913]\n",
      " [0.50700031 0.49299969]\n",
      " [0.53516124 0.46483876]\n",
      " [0.49622947 0.50377053]\n",
      " [0.52578979 0.47421021]\n",
      " [0.54006911 0.45993089]\n",
      " [0.42795261 0.57204739]\n",
      " [0.45671169 0.54328831]\n",
      " [0.56250794 0.43749206]\n",
      " [0.57658422 0.42341578]\n",
      " [0.45817104 0.54182896]\n",
      " [0.52242501 0.47757499]\n",
      " [0.51537148 0.48462852]\n",
      " [0.54247538 0.45752462]\n",
      " [0.46010769 0.53989231]\n",
      " [0.54844305 0.45155695]\n",
      " [0.5132167  0.4867833 ]\n",
      " [0.45689818 0.54310182]\n",
      " [0.55170109 0.44829891]\n",
      " [0.47344321 0.52655679]\n",
      " [0.52612855 0.47387145]\n",
      " [0.51735794 0.48264206]\n",
      " [0.58322863 0.41677137]\n",
      " [0.52463448 0.47536552]\n",
      " [0.50145539 0.49854461]\n",
      " [0.55829231 0.44170769]\n",
      " [0.55956523 0.44043477]\n",
      " [0.51018067 0.48981933]\n",
      " [0.52264735 0.47735265]\n",
      " [0.53414016 0.46585984]\n",
      " [0.49703907 0.50296093]\n",
      " [0.4935884  0.5064116 ]\n",
      " [0.54599866 0.45400134]\n",
      " [0.57010258 0.42989742]\n",
      " [0.52401337 0.47598663]\n",
      " [0.52820265 0.47179735]\n",
      " [0.5117887  0.4882113 ]\n",
      " [0.50944246 0.49055754]\n",
      " [0.47113539 0.52886461]\n",
      " [0.54113655 0.45886345]\n",
      " [0.54130058 0.45869942]\n",
      " [0.55659798 0.44340202]\n",
      " [0.53171246 0.46828754]\n",
      " [0.44695827 0.55304173]\n",
      " [0.49870784 0.50129216]\n",
      " [0.50020661 0.49979339]\n",
      " [0.51350885 0.48649115]\n",
      " [0.5269557  0.4730443 ]\n",
      " [0.51161356 0.48838644]\n",
      " [0.56904634 0.43095366]\n",
      " [0.54286315 0.45713685]\n",
      " [0.56816514 0.43183486]\n",
      " [0.49571311 0.50428689]\n",
      " [0.53229264 0.46770736]\n",
      " [0.52966085 0.47033915]\n",
      " [0.53229174 0.46770826]\n",
      " [0.43742514 0.56257486]\n",
      " [0.51560235 0.48439765]\n",
      " [0.51319781 0.48680219]\n",
      " [0.52636889 0.47363111]\n",
      " [0.43384923 0.56615077]\n",
      " [0.549149   0.450851  ]\n",
      " [0.54505617 0.45494383]\n",
      " [0.51361047 0.48638953]\n",
      " [0.55966099 0.44033901]\n",
      " [0.5342449  0.4657551 ]\n",
      " [0.55949281 0.44050719]\n",
      " [0.521577   0.478423  ]\n",
      " [0.58213629 0.41786371]\n",
      " [0.5156139  0.4843861 ]\n",
      " [0.53604232 0.46395768]\n",
      " [0.5468159  0.4531841 ]\n",
      " [0.53442797 0.46557203]\n",
      " [0.53720454 0.46279546]\n",
      " [0.46620739 0.53379261]\n",
      " [0.54298309 0.45701691]\n",
      " [0.53769426 0.46230574]\n",
      " [0.54582412 0.45417588]\n",
      " [0.51714596 0.48285404]\n",
      " [0.51579945 0.48420055]\n",
      " [0.53408561 0.46591439]\n",
      " [0.57042071 0.42957929]\n",
      " [0.57180371 0.42819629]\n",
      " [0.47951071 0.52048929]\n",
      " [0.52698549 0.47301451]\n",
      " [0.56673376 0.43326624]\n",
      " [0.58936295 0.41063705]\n",
      " [0.48900304 0.51099696]\n",
      " [0.45521544 0.54478456]\n",
      " [0.53805476 0.46194524]\n",
      " [0.54959149 0.45040851]\n",
      " [0.54300859 0.45699141]\n",
      " [0.54471595 0.45528405]\n",
      " [0.51855149 0.48144851]\n",
      " [0.52130897 0.47869103]\n",
      " [0.53875329 0.46124671]\n",
      " [0.45822729 0.54177271]\n",
      " [0.5583484  0.4416516 ]\n",
      " [0.519087   0.480913  ]\n",
      " [0.47685486 0.52314514]\n",
      " [0.5537294  0.4462706 ]\n",
      " [0.54889821 0.45110179]\n",
      " [0.48516796 0.51483204]\n",
      " [0.52636729 0.47363271]\n",
      " [0.5515602  0.4484398 ]\n",
      " [0.56446812 0.43553188]\n",
      " [0.5145948  0.4854052 ]\n",
      " [0.58729037 0.41270963]\n",
      " [0.51817853 0.48182147]\n",
      " [0.4892615  0.5107385 ]\n",
      " [0.53747099 0.46252901]\n",
      " [0.51932284 0.48067716]\n",
      " [0.48709513 0.51290487]\n",
      " [0.55846322 0.44153678]\n",
      " [0.52455453 0.47544547]\n",
      " [0.42122432 0.57877568]\n",
      " [0.55303538 0.44696462]\n",
      " [0.51023074 0.48976926]\n",
      " [0.53043151 0.46956849]\n",
      " [0.516432   0.483568  ]\n",
      " [0.53039949 0.46960051]\n",
      " [0.53633013 0.46366987]\n",
      " [0.5695158  0.4304842 ]\n",
      " [0.44116687 0.55883313]\n",
      " [0.48525824 0.51474176]\n",
      " [0.45316276 0.54683724]\n",
      " [0.49845899 0.50154101]\n",
      " [0.51975304 0.48024696]\n",
      " [0.51307874 0.48692126]\n",
      " [0.44896033 0.55103967]\n",
      " [0.50817523 0.49182477]\n",
      " [0.54900571 0.45099429]\n",
      " [0.47479145 0.52520855]\n",
      " [0.55372903 0.44627097]\n",
      " [0.54165513 0.45834487]\n",
      " [0.54305618 0.45694382]\n",
      " [0.51865996 0.48134004]\n",
      " [0.5340747  0.4659253 ]\n",
      " [0.54319557 0.45680443]\n",
      " [0.52874558 0.47125442]\n",
      " [0.5085078  0.4914922 ]\n",
      " [0.53691288 0.46308712]\n",
      " [0.4591272  0.5408728 ]\n",
      " [0.55465721 0.44534279]\n",
      " [0.53554411 0.46445589]\n",
      " [0.49849571 0.50150429]\n",
      " [0.4952607  0.5047393 ]\n",
      " [0.50529037 0.49470963]\n",
      " [0.52602806 0.47397194]\n",
      " [0.55960973 0.44039027]\n",
      " [0.56875216 0.43124784]\n",
      " [0.55878113 0.44121887]\n",
      " [0.52845437 0.47154563]\n",
      " [0.58479883 0.41520117]\n",
      " [0.56645022 0.43354978]\n",
      " [0.54080387 0.45919613]\n",
      " [0.53949137 0.46050863]\n",
      " [0.52879293 0.47120707]\n",
      " [0.54089994 0.45910006]\n",
      " [0.52617956 0.47382044]\n",
      " [0.52873031 0.47126969]\n",
      " [0.55103329 0.44896671]\n",
      " [0.54821755 0.45178245]\n",
      " [0.4889015  0.5110985 ]\n",
      " [0.55146641 0.44853359]\n",
      " [0.54913272 0.45086728]\n",
      " [0.45678941 0.54321059]\n",
      " [0.42815675 0.57184325]\n",
      " [0.55382523 0.44617477]\n",
      " [0.44968762 0.55031238]\n",
      " [0.50997173 0.49002827]\n",
      " [0.53893345 0.46106655]\n",
      " [0.52024248 0.47975752]\n",
      " [0.47711107 0.52288893]\n",
      " [0.55111724 0.44888276]\n",
      " [0.55789485 0.44210515]\n",
      " [0.54134925 0.45865075]\n",
      " [0.481826   0.518174  ]\n",
      " [0.54539194 0.45460806]\n",
      " [0.45583797 0.54416203]\n",
      " [0.5288845  0.4711155 ]\n",
      " [0.524302   0.475698  ]\n",
      " [0.54273316 0.45726684]\n",
      " [0.52763471 0.47236529]\n",
      " [0.53753504 0.46246496]\n",
      " [0.48899602 0.51100398]\n",
      " [0.51387324 0.48612676]\n",
      " [0.50542006 0.49457994]\n",
      " [0.5323807  0.4676193 ]\n",
      " [0.49380809 0.50619191]\n",
      " [0.46428798 0.53571202]\n",
      " [0.52913761 0.47086239]\n",
      " [0.50229494 0.49770506]\n",
      " [0.47465042 0.52534958]\n",
      " [0.53188151 0.46811849]\n",
      " [0.4692862  0.5307138 ]\n",
      " [0.52248776 0.47751224]\n",
      " [0.56466294 0.43533706]\n",
      " [0.55201394 0.44798606]\n",
      " [0.45960834 0.54039166]\n",
      " [0.56245521 0.43754479]\n",
      " [0.52792898 0.47207102]\n",
      " [0.49565538 0.50434462]\n",
      " [0.46553242 0.53446758]\n",
      " [0.53924362 0.46075638]\n",
      " [0.52122988 0.47877012]\n",
      " [0.52685593 0.47314407]\n",
      " [0.55914308 0.44085692]\n",
      " [0.53872993 0.46127007]\n",
      " [0.47290856 0.52709144]\n",
      " [0.51101061 0.48898939]\n",
      " [0.55223935 0.44776065]\n",
      " [0.54439244 0.45560756]\n",
      " [0.54149911 0.45850089]\n",
      " [0.45967445 0.54032555]\n",
      " [0.52679161 0.47320839]\n",
      " [0.49298759 0.50701241]\n",
      " [0.55231011 0.44768989]\n",
      " [0.47537582 0.52462418]\n",
      " [0.53495031 0.46504969]\n",
      " [0.51012825 0.48987175]\n",
      " [0.5247563  0.4752437 ]\n",
      " [0.58599521 0.41400479]\n",
      " [0.54311683 0.45688317]\n",
      " [0.58217807 0.41782193]\n",
      " [0.52691521 0.47308479]\n",
      " [0.53783537 0.46216463]\n",
      " [0.44610891 0.55389109]\n",
      " [0.51751892 0.48248108]\n",
      " [0.48215632 0.51784368]\n",
      " [0.52090017 0.47909983]\n",
      " [0.53991855 0.46008145]\n",
      " [0.51267926 0.48732074]\n",
      " [0.54160481 0.45839519]\n",
      " [0.52683136 0.47316864]\n",
      " [0.50457154 0.49542846]\n",
      " [0.50081823 0.49918177]\n",
      " [0.51605907 0.48394093]\n",
      " [0.49362742 0.50637258]\n",
      " [0.50602088 0.49397912]\n",
      " [0.51016868 0.48983132]\n",
      " [0.47974145 0.52025855]\n",
      " [0.52075262 0.47924738]\n",
      " [0.54765033 0.45234967]\n",
      " [0.55831842 0.44168158]\n",
      " [0.45014439 0.54985561]\n",
      " [0.50489825 0.49510175]\n",
      " [0.54637385 0.45362615]\n",
      " [0.48870397 0.51129603]\n",
      " [0.57757713 0.42242287]\n",
      " [0.561849   0.438151  ]\n",
      " [0.55344095 0.44655905]\n",
      " [0.53918385 0.46081615]\n",
      " [0.52658672 0.47341328]\n",
      " [0.52936053 0.47063947]\n",
      " [0.49494008 0.50505992]\n",
      " [0.53579623 0.46420377]\n",
      " [0.51905707 0.48094293]\n",
      " [0.60187923 0.39812077]\n",
      " [0.56248305 0.43751695]\n",
      " [0.57710689 0.42289311]\n",
      " [0.57505605 0.42494395]\n",
      " [0.54855877 0.45144123]\n",
      " [0.53046559 0.46953441]\n",
      " [0.53664641 0.46335359]\n",
      " [0.54136469 0.45863531]\n",
      " [0.53504741 0.46495259]\n",
      " [0.46080533 0.53919467]\n",
      " [0.49917648 0.50082352]\n",
      " [0.47307652 0.52692348]\n",
      " [0.55855831 0.44144169]\n",
      " [0.48249136 0.51750864]\n",
      " [0.51196024 0.48803976]\n",
      " [0.53329887 0.46670113]\n",
      " [0.54737607 0.45262393]\n",
      " [0.51303317 0.48696683]\n",
      " [0.44609725 0.55390275]\n",
      " [0.56521253 0.43478747]\n",
      " [0.5118932  0.4881068 ]\n",
      " [0.54435712 0.45564288]\n",
      " [0.54139312 0.45860688]\n",
      " [0.52189921 0.47810079]\n",
      " [0.56274424 0.43725576]\n",
      " [0.56648613 0.43351387]\n",
      " [0.43200821 0.56799179]\n",
      " [0.54796565 0.45203435]\n",
      " [0.53088213 0.46911787]\n",
      " [0.49587152 0.50412848]\n",
      " [0.5754041  0.4245959 ]\n",
      " [0.53388573 0.46611427]\n",
      " [0.55342987 0.44657013]\n",
      " [0.55009308 0.44990692]\n",
      " [0.50681209 0.49318791]\n",
      " [0.5294141  0.4705859 ]\n",
      " [0.55862833 0.44137167]\n",
      " [0.46937136 0.53062864]\n",
      " [0.55423382 0.44576618]\n",
      " [0.56047784 0.43952216]\n",
      " [0.50336926 0.49663074]\n",
      " [0.54967835 0.45032165]\n",
      " [0.50502422 0.49497578]\n",
      " [0.527176   0.472824  ]\n",
      " [0.56987461 0.43012539]\n",
      " [0.49877224 0.50122776]\n",
      " [0.52318979 0.47681021]\n",
      " [0.51269225 0.48730775]\n",
      " [0.52597665 0.47402335]\n",
      " [0.56605946 0.43394054]\n",
      " [0.535316   0.464684  ]\n",
      " [0.53292108 0.46707892]\n",
      " [0.52653225 0.47346775]\n",
      " [0.50310641 0.49689359]\n",
      " [0.52654754 0.47345246]\n",
      " [0.52246751 0.47753249]\n",
      " [0.46444898 0.53555102]\n",
      " [0.52718657 0.47281343]\n",
      " [0.526734   0.473266  ]\n",
      " [0.53493238 0.46506762]\n",
      " [0.5194834  0.4805166 ]\n",
      " [0.52538715 0.47461285]\n",
      " [0.57612882 0.42387118]\n",
      " [0.50900602 0.49099398]\n",
      " [0.51573128 0.48426872]\n",
      " [0.54739524 0.45260476]\n",
      " [0.54944245 0.45055755]\n",
      " [0.5401123  0.4598877 ]\n",
      " [0.5282023  0.4717977 ]\n",
      " [0.53539907 0.46460093]\n",
      " [0.50956689 0.49043311]\n",
      " [0.54274734 0.45725266]\n",
      " [0.46684393 0.53315607]\n",
      " [0.4928168  0.5071832 ]\n",
      " [0.53542041 0.46457959]\n",
      " [0.53459428 0.46540572]\n",
      " [0.55277245 0.44722755]\n",
      " [0.56327525 0.43672475]\n",
      " [0.54945138 0.45054862]\n",
      " [0.52357402 0.47642598]\n",
      " [0.52864175 0.47135825]\n",
      " [0.53097234 0.46902766]\n",
      " [0.48673301 0.51326699]\n",
      " [0.52582194 0.47417806]\n",
      " [0.55608164 0.44391836]\n",
      " [0.48947545 0.51052455]\n",
      " [0.54301173 0.45698827]\n",
      " [0.56634657 0.43365343]\n",
      " [0.54092042 0.45907958]\n",
      " [0.37718924 0.62281076]\n",
      " [0.55481781 0.44518219]\n",
      " [0.49301489 0.50698511]\n",
      " [0.56087469 0.43912531]\n",
      " [0.57150877 0.42849123]\n",
      " [0.52817693 0.47182307]\n",
      " [0.54987498 0.45012502]\n",
      " [0.51503783 0.48496217]\n",
      " [0.42922602 0.57077398]\n",
      " [0.49838307 0.50161693]\n",
      " [0.55997617 0.44002383]\n",
      " [0.55723404 0.44276596]\n",
      " [0.52470835 0.47529165]\n",
      " [0.53252062 0.46747938]\n",
      " [0.52193568 0.47806432]\n",
      " [0.56470701 0.43529299]\n",
      " [0.53235652 0.46764348]\n",
      " [0.53734572 0.46265428]\n",
      " [0.5489834  0.4510166 ]\n",
      " [0.52543831 0.47456169]\n",
      " [0.53297546 0.46702454]\n",
      " [0.49438261 0.50561739]\n",
      " [0.56910351 0.43089649]\n",
      " [0.56125455 0.43874545]\n",
      " [0.46916419 0.53083581]\n",
      " [0.55636962 0.44363038]\n",
      " [0.52688471 0.47311529]\n",
      " [0.4925628  0.5074372 ]\n",
      " [0.49024845 0.50975155]\n",
      " [0.51920504 0.48079496]\n",
      " [0.52521156 0.47478844]\n",
      " [0.5086893  0.4913107 ]\n",
      " [0.53460165 0.46539835]\n",
      " [0.52990636 0.47009364]\n",
      " [0.47549611 0.52450389]\n",
      " [0.50738204 0.49261796]\n",
      " [0.54706996 0.45293004]\n",
      " [0.50533934 0.49466066]\n",
      " [0.50020774 0.49979226]\n",
      " [0.52440436 0.47559564]\n",
      " [0.54986713 0.45013287]\n",
      " [0.50971254 0.49028746]\n",
      " [0.49550567 0.50449433]\n",
      " [0.53565388 0.46434612]\n",
      " [0.52812566 0.47187434]\n",
      " [0.50867006 0.49132994]\n",
      " [0.495204   0.504796  ]\n",
      " [0.53450259 0.46549741]\n",
      " [0.52133    0.47867   ]\n",
      " [0.55942965 0.44057035]\n",
      " [0.54433569 0.45566431]\n",
      " [0.53319866 0.46680134]\n",
      " [0.52077263 0.47922737]\n",
      " [0.52227585 0.47772415]\n",
      " [0.5489791  0.4510209 ]\n",
      " [0.5211292  0.4788708 ]\n",
      " [0.51692935 0.48307065]\n",
      " [0.50427341 0.49572659]\n",
      " [0.49959825 0.50040175]\n",
      " [0.54327551 0.45672449]\n",
      " [0.53105165 0.46894835]\n",
      " [0.55993075 0.44006925]\n",
      " [0.53542494 0.46457506]\n",
      " [0.54978822 0.45021178]\n",
      " [0.5277766  0.4722234 ]\n",
      " [0.51991623 0.48008377]\n",
      " [0.49892762 0.50107238]\n",
      " [0.54125824 0.45874176]\n",
      " [0.52898277 0.47101723]\n",
      " [0.4864341  0.5135659 ]\n",
      " [0.54534963 0.45465037]\n",
      " [0.55287206 0.44712794]\n",
      " [0.45213295 0.54786705]\n",
      " [0.55160746 0.44839254]\n",
      " [0.46295932 0.53704068]\n",
      " [0.53774406 0.46225594]\n",
      " [0.4994333  0.5005667 ]\n",
      " [0.44952458 0.55047542]\n",
      " [0.52508294 0.47491706]\n",
      " [0.50742751 0.49257249]\n",
      " [0.52026497 0.47973503]\n",
      " [0.52104918 0.47895082]\n",
      " [0.49668876 0.50331124]\n",
      " [0.55722165 0.44277835]\n",
      " [0.51324519 0.48675481]\n",
      " [0.46995931 0.53004069]\n",
      " [0.53552696 0.46447304]\n",
      " [0.53041067 0.46958933]\n",
      " [0.5565709  0.4434291 ]\n",
      " [0.53904489 0.46095511]\n",
      " [0.53897276 0.46102724]\n",
      " [0.53361977 0.46638023]\n",
      " [0.52083857 0.47916143]\n",
      " [0.52543503 0.47456497]\n",
      " [0.53490921 0.46509079]\n",
      " [0.55580098 0.44419902]\n",
      " [0.57776975 0.42223025]]\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод вероятностей\n",
    "probabilities = model.predict_proba(X_test)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ml_predictions.txt', probabilities, fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     up_predict  down_predict  up_real  down_real  profit_loss\n",
      "0      0.558514      0.441486      1.0        0.0            1\n",
      "5      0.567620      0.432380      0.0        1.0            0\n",
      "10     0.564317      0.435683      0.0        1.0            0\n",
      "29     0.427953      0.572047      0.0        1.0            1\n",
      "31     0.562508      0.437492      0.0        1.0            0\n",
      "32     0.576584      0.423416      1.0        0.0            1\n",
      "41     0.551701      0.448299      0.0        1.0            0\n",
      "45     0.583229      0.416771      1.0        0.0            1\n",
      "48     0.558292      0.441708      1.0        0.0            1\n",
      "49     0.559565      0.440435      0.0        1.0            0\n",
      "..          ...           ...      ...        ...          ...\n",
      "395    0.556370      0.443630      1.0        0.0            1\n",
      "419    0.559430      0.440570      1.0        0.0            1\n",
      "431    0.559931      0.440069      0.0        1.0            0\n",
      "441    0.552872      0.447128      0.0        1.0            0\n",
      "443    0.551607      0.448393      0.0        1.0            0\n",
      "447    0.449525      0.550475      0.0        1.0            1\n",
      "453    0.557222      0.442778      1.0        0.0            1\n",
      "458    0.556571      0.443429      0.0        1.0            0\n",
      "465    0.555801      0.444199      1.0        0.0            1\n",
      "466    0.577770      0.422230      0.0        1.0            0\n",
      "(105, 5)\n"
     ]
    }
   ],
   "source": [
    "border = 0.55  # Пороговое значение вероятности по предсказанию\n",
    "\n",
    "def profit_loss(u_p, d_p, u_r, d_r):\n",
    "    if u_p > border and u_r == 1.0:\n",
    "        return 1\n",
    "    elif d_p > border and d_r == 1.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df = pd.DataFrame(probabilities, columns=['up_predict', 'down_predict'])\n",
    "df_y = pd.DataFrame(y_test_2, columns=['up_real', 'down_real'])\n",
    "df = pd.merge(df, df_y, left_index=True, right_index=True)  # , suffixes=('_predict', '_real')\n",
    "df = df[(df.up_predict > border) | (df.down_predict > border)]  # Отсекаем неудовлетворяющие строки\n",
    "df['profit_loss'] = df.apply(lambda x: profit_loss(x.up_predict, x.down_predict, x.up_real, x.down_real), axis=1)\n",
    "print(df.to_string(max_rows=20, max_cols=22))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "rez = df.profit_loss.sum() / len(df.profit_loss)\n",
    "print(rez)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
