{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call и Put отдельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TRADEDATE      OPEN       LOW      HIGH     CLOSE  ...  SHORTNAME   LSTTRADE up_down  next_ud  next_name\n",
      "0    2015-01-05   76930.0   72470.0   78980.0   74600.0  ...   RTS-3.15 2015-03-16       0        0   RTS-3.15\n",
      "1    2015-01-06   74470.0   71200.0   74610.0   73480.0  ...   RTS-3.15 2015-03-16       0        1   RTS-3.15\n",
      "...         ...       ...       ...       ...       ...  ...        ...        ...     ...      ...        ...\n",
      "2328 2024-06-11  112490.0  110680.0  112630.0  111640.0  ...   RTS-6.24 2024-06-20       0        1   RTS-6.24\n",
      "2329 2024-06-13  111560.0  106020.0  112790.0  111700.0  ...   RTS-6.24 2024-06-20       1        1   RTS-6.24\n",
      "(2330, 11)\n",
      "\n",
      "         TRADEDATE  OPENPOSITION      NAME   LSTTRADE OPTIONTYPE  STRIKE\n",
      "0      2015-01-05         18004  RTS-3.15 2015-01-15          C  100000\n",
      "1      2015-01-05             0  RTS-3.15 2015-03-16          C   45000\n",
      "...           ...           ...       ...        ...        ...     ...\n",
      "749566 2024-06-14             0  RTS-6.24 2024-06-20          P  155000\n",
      "749567 2024-06-14           472  RTS-6.24 2024-06-20          P   97500\n",
      "(749568, 6)\n"
     ]
    }
   ],
   "source": [
    "tiker: str = 'RTS'\n",
    "db_path: Path = Path(fr'c:\\Users\\Alkor\\gd\\data_quote_db\\{tiker}_futures_options_day_pj1.db')\n",
    "\n",
    "# # Путь к файлу базы данных\n",
    "# db_path = 'path/to/your/database.db'\n",
    "\n",
    "# Подключение к базе данных\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Чтение данных из таблицы в DataFrame\n",
    "df_f = pd.read_sql_query(\"SELECT `TRADEDATE`, `OPEN`, `LOW`, `HIGH`, `CLOSE`, `OPENPOSITION`, `SHORTNAME`, `LSTTRADE` FROM Futures\", conn)\n",
    "df_o = pd.read_sql_query(\"SELECT `TRADEDATE`, `OPENPOSITION`, `NAME`, `LSTTRADE`, `OPTIONTYPE`, `STRIKE` FROM Options\", conn)\n",
    "\n",
    "# Закрытие соединения\n",
    "conn.close()\n",
    "\n",
    "df_f[['TRADEDATE', 'LSTTRADE']] = df_f[['TRADEDATE', 'LSTTRADE']].apply(pd.to_datetime)\n",
    "df_o[['TRADEDATE', 'LSTTRADE']] = df_o[['TRADEDATE', 'LSTTRADE']].apply(pd.to_datetime)\n",
    "\n",
    "df_o = df_o[df_o.TRADEDATE < df_o.LSTTRADE]\n",
    "df_f['up_down'] = df_f[['OPEN', 'CLOSE']].apply(lambda x: 1 if (x.CLOSE > x.OPEN) else 0, axis=1)  # Добавление колонки направления свечи\n",
    "df_f['next_ud'] = df_f.up_down.shift(-1)  # Добавление колонки с направление следующей свечи\n",
    "df_f['next_name'] = df_f.SHORTNAME.shift(-1)  # Добавление колонки с именем следующей свечи\n",
    "\n",
    "# Фильтрация строк, где значения в столбцах SHORTNAME и next_name равны (исключение переходов контракта)\n",
    "df_f = df_f[df_f['SHORTNAME'] == df_f['next_name']]\n",
    "\n",
    "# print(df_f.to_string(max_rows=4, max_cols=10))\n",
    "df_f = df_f.dropna()\n",
    "df_f[['next_ud']] = df_f[['next_ud']].astype(int)\n",
    "\n",
    "# Сортировка по полю даты и сброс индекса\n",
    "df_f = df_f.sort_values(by='TRADEDATE').reset_index(drop=True)\n",
    "df_o = df_o.sort_values(by='TRADEDATE').reset_index(drop=True)\n",
    "\n",
    "# Вывод DataFrame\n",
    "# print(df_f)\n",
    "# print(df_o)\n",
    "print(df_f.to_string(max_rows=4, max_cols=10))\n",
    "print(df_f.shape)\n",
    "print('\\n', df_o.to_string(max_rows=4, max_cols=10))\n",
    "print(df_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0       1   2       3    4       5    6       7     8       9   ...     33      34     35      36     37      38     39      40     41  42\n",
      "0     32  142880  32  134086   82  133628   88  123734   320  123342  ...  43722  111124  35032  127184  35030  127598  33476  154632  33474   0\n",
      "1      0  140820  32  140786   32  132186   82  131728    88  121840  ...  44032  113784  43718  115044  35028  131088  35026  131502  33476   1\n",
      "2     82  138438  88  128360  316  127944  422  115414  6490  114138  ...  35020  141258  33474  168608  33472  168608  28912  186234  28912   0\n",
      "3     32  142188  82  141680   92  131924  314  131504   420  118712  ...  35028  149064  35026  150284  33478  178592  33476  178592  28912   0\n",
      "4     30  155208  30  146434   80  145926   90  135732   306  135308  ...  43722  136822  35030  156592  35028  157812  33480  186692  33478   0\n",
      "...   ..     ...  ..     ...  ...     ...  ...     ...   ...     ...  ...    ...     ...    ...     ...    ...     ...    ...     ...    ...  ..\n",
      "2325   0   39078   0   38842    0   36080    0   35928     0   32952  ...     80   44420     78   44592     32   44624     30   44642     10   1\n",
      "2326   0   47772   0   45010    0   44858    0   41292     0   40714  ...     78   55130     32   55162     30   55180     10   55236      0   0\n",
      "2327   0   50488   0   50252    0   47490    0   47318     0   43712  ...     80   57674     78   57912     32   57944     30   57962     10   0\n",
      "2328   0   52374   0   52138    0   49356    0   49164     0   45542  ...     80   61638     78   61876     32   61908     30   61926     10   1\n",
      "2329   0   35044   0   34808    0   32070    0   31918     0   28884  ...     80   42202     78   42440     32   42472     30   42490     10   1\n"
     ]
    }
   ],
   "source": [
    "step_strike = 2500\n",
    "\n",
    "df_rez = pd.DataFrame()\n",
    "\n",
    "for row in df_f.itertuples():  # Перебираем даты для запроса торгуемых опционов на эту дату\n",
    "    df = df_o[df_o.TRADEDATE == row.TRADEDATE]\n",
    "    # print(df.to_string(max_rows=4, max_cols=10))\n",
    "    df_p = (\n",
    "        df.query('OPTIONTYPE ==  \"P\"')\n",
    "        .groupby(['STRIKE'], as_index=False)\n",
    "        .agg({'OPENPOSITION': 'sum'})\n",
    "        .sort_values(['STRIKE'], ascending=True)\n",
    "        .rename(columns={'OPENPOSITION': 'oi_p'})\n",
    "    )\n",
    "    # print(df_p.to_string(max_rows=4, max_cols=10))\n",
    "    # print(df_p.shape)\n",
    "    \n",
    "    df_c = (\n",
    "        df.query('OPTIONTYPE ==  \"C\"')\n",
    "        .groupby(['STRIKE'], as_index=False)\n",
    "        .agg({'OPENPOSITION': 'sum'})\n",
    "        .sort_values(['STRIKE'], ascending=True)\n",
    "        .rename(columns={'OPENPOSITION': 'oi_c'})\n",
    "    )\n",
    "    # print(df_c.to_string(max_rows=4, max_cols=10))\n",
    "    # print(df_c.shape)\n",
    "    \n",
    "    # Временный DF для слияния, чтобы исключить пропуски страйков\n",
    "    df_tmp = pd.DataFrame(columns=['STRIKE'])\n",
    "    for st in range(df.STRIKE.min(), df.STRIKE.max() + step_strike, step_strike):\n",
    "        # Новое значение для добавления\n",
    "        new_row = pd.DataFrame({'STRIKE': [st]})\n",
    "        # Добавление новой строки в DataFrame с помощью concat\n",
    "        df_tmp = pd.concat([df_tmp, new_row], ignore_index=True)\n",
    "    # print(df_tmp.to_string(max_rows=4, max_cols=10))\n",
    "    \n",
    "    # Выполнение полного внешнего соединения по столбцу STRIKE\n",
    "    merged_df = pd.merge(df_p, df_c, on='STRIKE', how='outer')\n",
    "    merged_df = pd.merge(merged_df, df_tmp, on='STRIKE', how='outer')\n",
    "    # Приведение типов с помощью infer_objects\n",
    "    merged_df = merged_df.infer_objects(copy=False)\n",
    "    \n",
    "    merged_df = merged_df.fillna(0)\n",
    "    merged_df[['STRIKE', 'oi_c', 'oi_p']] = merged_df[['STRIKE', 'oi_c', 'oi_p']].astype(int)\n",
    "    # print(merged_df.to_string(max_rows=4, max_cols=10))\n",
    "    # print(merged_df.shape)\n",
    "    \n",
    "    merged_df['oi_c'] = merged_df['oi_c'].cumsum()\n",
    "    merged_df['oi_p'] = merged_df.iloc[::-1]['oi_p'].cumsum()[::-1]\n",
    "    # print(merged_df.to_string(max_rows=4, max_cols=10))\n",
    "    \n",
    "    # Записываем в переменную значение цены CLOSE фьючерса\n",
    "    price_close = df_f.loc[df_f['TRADEDATE'] == row.TRADEDATE, 'CLOSE'].values[0]\n",
    "    # Расчитываем ближайший страйк\n",
    "    nearest_strike = round(price_close / step_strike) * step_strike\n",
    "    # print(price_close, nearest_strike)\n",
    "    \n",
    "    # Список индексов со значением nearest_strike из поля merged_df['STRIKE']\n",
    "    index = merged_df.index[merged_df['STRIKE'] == nearest_strike].tolist()\n",
    "    # Известный индекс строки (берем 0)\n",
    "    index = index[0]\n",
    "    # Определение диапазона строк\n",
    "    start_index = max(0, index - 10)\n",
    "    end_index = min(len(df), index + 10 + 1)\n",
    "    # Получение 10 строк до и 10 строк после строки с известным индексом\n",
    "    subset_df = merged_df.iloc[start_index:end_index]\n",
    "    # print(subset_df.to_string(max_rows=40, max_cols=10))\n",
    "    \n",
    "    # Объединение двух столбцов в один список\n",
    "    features_lst = subset_df[['oi_c', 'oi_p']].values.flatten().tolist()\n",
    "    # print(features_lst)\n",
    "    \n",
    "    # Создание списка списков\n",
    "    list_of_lists = [features_lst[i:i+1] for i in range(0, len(features_lst), 1)]\n",
    "    # print(list_of_lists)\n",
    "    \n",
    "    # data = np.array(list_of_lists)\n",
    "    # scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # normalized_data = scaler.fit_transform(data)\n",
    "    # # print(normalized_data)\n",
    "    \n",
    "    features_lst.append(row.next_ud)\n",
    "    # print(features_lst)\n",
    "    \n",
    "    # writer = csv.writer(f)\n",
    "    # writer.writerows(features_lst)\n",
    "    \n",
    "    # # Создание DataFrame с одной строкой\n",
    "    # df = pd.DataFrame([features_lst])\n",
    "    \n",
    "    if len(df_rez) == 0:\n",
    "        df_rez = pd.DataFrame(features_lst).T\n",
    "    else:\n",
    "        # Добавление новой строки с использованием loc\n",
    "        df_rez.loc[len(df_rez)] = features_lst\n",
    "    # break\n",
    "    \n",
    "print(df_rez.to_string(max_rows=10, max_cols=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение DF в файл без индекса\n",
    "df_rez.to_csv(fr'../nn_features_and_target.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
